<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>分类: 机器学习 - Robin&#039;s Wo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Robin&#039;s Wo"><meta name="msapplication-TileImage" content="/img/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Robin&#039;s Wo"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Robin，80后，主业iOS开发，移动开发者，热爱技术，学习中。很高兴能够在这里与你分享对技术对生活的思考与记录。"><meta property="og:type" content="blog"><meta property="og:title" content="Robin&#039;s Wo"><meta property="og:url" content="https://zycslog.github.io/"><meta property="og:site_name" content="Robin&#039;s Wo"><meta property="og:description" content="Robin，80后，主业iOS开发，移动开发者，热爱技术，学习中。很高兴能够在这里与你分享对技术对生活的思考与记录。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zycslog.github.io/img/og_image.png"><meta property="article:author" content="Robin"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zycslog.github.io"},"headline":"Robin's Wo","image":["https://zycslog.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Robin"},"publisher":{"@type":"Organization","name":"Robin's Wo","logo":{"@type":"ImageObject","url":"https://zycslog.github.io/img/avatar.jpg"}},"description":"Robin，80后，主业iOS开发，移动开发者，热爱技术，学习中。很高兴能够在这里与你分享对技术对生活的思考与记录。"}</script><link rel="alternate" href="/atom.xml" title="Robin&#039;s Wo" type="application/atom+xml"><link rel="icon" href="/img/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/avatar.jpg" alt="Robin&#039;s Wo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/categories/Logs/">Log</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zycslog"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">分类</a></li><li class="is-active"><a href="#" aria-current="page">机器学习</a></li></ul></nav></div></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/04/30/2018-08-28-coreml-vs-mlkit/"><img class="fill" src="/images/coreml-vs-mlkit/cover.jpeg" alt="Core ML vs ML Kit：哪一个移动端机器学习框架更适合你？"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:35:13.804Z" title="4/30/2022, 2:35:13 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T07:42:16.470Z" title="4/30/2022, 3:42:16 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">13 分钟读完 (大约1946个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2018-08-28-coreml-vs-mlkit/">Core ML vs ML Kit：哪一个移动端机器学习框架更适合你？</a></h1><div class="content"><p>截止2018年举行的Apple全球开发者大会（WWDC2018），Apple公司的用于iOS设备的机器学习框架CoreML走过了一年的更新迭代，迎来了首次较大规模的版本更新。在同一时期，Google也发布了其一款面向iOS和安卓设备的跨平台人工智能开发框架。这两类工具的目的均是为了优化大型人工智能模型和数据集开发的负担，使得开发者能够以轻量化的实现方式，增加移动应用程序的智能化等。但是值得思考的一点是，为什么在这个时期，Google和Apple会相继推出自家的移动端机器学习框架呢？</p></div><a class="article-more button is-small is-size-7" href="/2022/04/30/2018-08-28-coreml-vs-mlkit/#more">阅读更多</a></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/04/30/2019-09-07-machine-learning-feature/"><img class="fill" src="/images/MLFeature/cover.jpeg" alt="机器学习与移动应用开发的未来"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:35:13.802Z" title="4/30/2022, 2:35:13 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T07:45:41.449Z" title="4/30/2022, 3:45:41 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">18 分钟读完 (大约2699个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2019-09-07-machine-learning-feature/">机器学习与移动应用开发的未来</a></h1><div class="content"><p>移动开发者可以从设备上的机器学习（on-device machine learning）所能提供的革命性变化中获益匪浅。这是因为该技术能够支持移动应用程序，即允许通过利用强大的功能来实现更流畅的用户体验，例如提供准确的基于地理位置的建议或即时检测植物疾病等。</p>
<p>移动机器学习（mobile machine learning）的这种快速发展已经成为是对经典机器学习（classical machine learning）所面临的许多常见问题的回应。事实上，这些问题即将发生。未来的移动应用将需要更快的处理速度和更低的延迟。</p>
<p>你可能会疑问为什么人工智能优先的移动应用程序（AI-first mobile applications）不能简单地在云端中进行推理运算。首先，云技术依赖于中央节点（设想一个拥有大量存储空间和计算能力的大型数据中心）。而这种集中式的方式无法满足创建流畅的、基于机器学习驱动的移动用户体验所需的处理速度。因为数据必须在这个集中式数据中心进行处理，然后将结果发送回设备。这需要花费时间和金钱，并且很难保证数据的隐私。</p>
<p>在概述了移动机器学习的这些核心优势之后，下面让我们更详细地探讨为什么作为移动应用开发者，你会希望继续关注即将到来的设备机器学习革命。</p></div><a class="article-more button is-small is-size-7" href="/2022/04/30/2019-09-07-machine-learning-feature/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:35:13.799Z" title="4/30/2022, 2:35:13 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T07:45:17.541Z" title="4/30/2022, 3:45:17 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">16 分钟读完 (大约2350个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2018-08-02-novelty-detection/">异常点检测算法小结</a></h1><div class="content"><p>异常点检测，有时也叫离群点检测，英文一般叫做Novelty Detection或者Outlier Detection,是比较常见的一类非监督学习算法，这里就对异常点检测算法做一个总结。</p>
<h2 id="异常点检测算法使用场景"><a href="#异常点检测算法使用场景" class="headerlink" title="异常点检测算法使用场景"></a>异常点检测算法使用场景</h2><p>什么时候我们需要异常点检测算法呢？常见的有三种情况。</p>
<ol>
<li>在做特征工程的时候需要对异常的数据做过滤，防止对归一化等处理的结果产生影响。</li>
<li>对没有标记输出的特征数据做筛选，找出异常的数据。</li>
<li>对有标记输出的特征数据做二分类时，由于某些类别的训练样本非常少，类别严重不平衡，此时也可以考虑用非监督的异常点检测算法来做。</li>
</ol></div><a class="article-more button is-small is-size-7" href="/2022/04/30/2018-08-02-novelty-detection/#more">阅读更多</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:35:13.796Z" title="4/30/2022, 2:35:13 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T07:45:05.377Z" title="4/30/2022, 3:45:05 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">1 小时读完 (大约11266个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2018-09-20-Introduction_Of_Machine_Learning/">机器学习基础介绍</a></h1><div class="content"><p><strong>机器学习是一门从数据中提取知识的技术。</strong> 它是统计学、人工智能和计算机科学的交叉研究领域，被常被称为<strong>预测分析</strong>、<strong>统计学习</strong>。机器学习方法的应用近年来在日常生活中无处不在。从自动推荐看哪部电影、点什么食物或买什么东西，到个性化的在线收音机、智能化在线教育，再到从照片中找到你的朋友等等需要现代网站和设备的核心都是机器学习算法。当你查看例如Facebook、Amazon、Netflix、Weibo、Twitter等复杂网站时，很可能网站的每个部分都包含了多个机器学习模型。</p>
<p>除了商业应用之外，机器学习已经对数据驱动的研究方式产生了巨大的影响。机器学习相关的技术、工具已经应用于各种科学问题，例如理解恒星、发现遥远的行星、发现新的粒子、分析DNA序列以及提供个性化的癌症治疗等。</p>
<p>但是，为了从机器学习中获益，你的应用程序可能并不需要大规模。在本部分，将解释为什么机器学习变的如此的流行，并讨论使用机器学习可以解决哪些问题。然后，将展示如何构建你的第一个机器学习模型等。</p>
<h2 id="为什么是机器学习？"><a href="#为什么是机器学习？" class="headerlink" title="为什么是机器学习？"></a>为什么是机器学习？</h2><p>较早期的“智能”应用程序，许多的系统使用“if”和“else”硬编码规则来处理数据或者根据用户的输入进行调整。想象一个垃圾邮件过滤器，其工作是适当的移动电子邮件到垃圾邮件文件夹。你可以构造一个垃圾邮件词库黑名单，并返回垃圾邮件标记 <em>1</em>。这是一个使用专家设计的规则来实现“智能”应用程序的例子。手工创建决策规则对于一些应用程序是可行的，特别是那些人类对建模过程有很好理解的应用程序，然而，使用手工编码的规则进行决策有两点主要缺点：</p>
<ul>
<li>做出决策所需的规则逻辑是针对特定的单个域和任务的，一些业务改变，整个系统可能都需要重写；</li>
<li>设计规则需要深刻理解人类专家应该如何做出决定。</li>
</ul></div><a class="article-more button is-small is-size-7" href="/2022/04/30/2018-09-20-Introduction_Of_Machine_Learning/#more">阅读更多</a></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/04/30/2019-01-22-keras_mnist_for_iOS/"><img class="fill" src="/images/keras-mnist-for-ios/cover.jpg" alt="从Keras开始构建iOS平台手写数字实时识别"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:34:32.164Z" title="4/30/2022, 2:34:32 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T06:34:32.164Z" title="4/30/2022, 2:34:32 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">36 分钟读完 (大约5406个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2019-01-22-keras_mnist_for_iOS/">从Keras开始构建iOS平台手写数字实时识别</a></h1><div class="content"><p>本文将介绍如何构建和训练一个深度学习网络来识别手写数字，以及如何将训练所得的深度网络模型转换为iOS平台的机器学习框架CoreML格式，并集成进iOS应用程序中以实时识别数字等。</p>
<h1 id="10步之内完成模型的构建、训练和发布使用"><a href="#10步之内完成模型的构建、训练和发布使用" class="headerlink" title="10步之内完成模型的构建、训练和发布使用"></a><strong>10步之内完成模型的构建、训练和发布使用</strong></h1><p><strong>TLDR；</strong></p>
<p>本文中暂时不会介绍卷积神经网络的细节内容，例如如何使用卷积层、池化层训练深度学习网络，以及如何使用预训练模型识别目标等，相关卷积神经网络细节的内容将会放在本文内容之后，进行详细的介绍。本文旨在介绍如何一步一步的从数据的获取、整理、模型的构建、训练以及后面的格式转换、使用等介绍Keras框架的基本使用和如何使用CoreML体系在一个实实在在的应用程序中使用模型等。</p>
<p>下图是最终结果的预览：</p>
<p><img src="https://liip.rokka.io/www_inarticle/812493/output.gif"></p>
<p>接下来，开始一步步的实现相关的过程等。</p>
<h2 id="1-如何开始"><a href="#1-如何开始" class="headerlink" title="1. 如何开始"></a>1. <strong>如何开始</strong></h2><p>To have a fully working example I thought we’d start with a toy dataset like the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST set of handwritten letters</a> and train a deep learning network to recognize those. Once it’s working nicely on our PC, we will port it to an iPhone X using the <a target="_blank" rel="noopener" href="https://developer.apple.com/documentation/coreml">CoreML standard</a>.</p>
<p>在计算机程序设计学习的过程中，几乎都是以一个经典的“Hello World”程序开始的。而在机器学习领域，同样具有类似“Hello World”的一个经典入门级数据集——<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>，该数据集是一系列手写数字0到9的图片文件，这里的目的是使用这个数据集训练一个深度学习网络来识别它们。在开始之前，你或许对iOS平台的CoreML以及keras还很陌生，你可以先了解一下它们的体系和设计：</p>
<ul>
<li>CoreML：</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://developer.apple.com/documentation/coreml">Core ML | Apple Developer Documentation</a></p>
<ul>
<li>Keras：</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://keras.io/zh/">Keras 中文文档</a></p>
<h2 id="2-获取数据"><a href="#2-获取数据" class="headerlink" title="2. 获取数据"></a>2. 获取数据</h2><p>在大多数的Python机器学习类库中，都有内置的数据集访问接口，以方便使用者的使用，在Keras中也不例外，可以很方便的使用其内置的数据集访问接口获取数据集，具体的接口定义在<code>keras.datasets</code>中，具体的使用如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用Keras内置数据集访问接口导入数据集并对数据集进行转换</span></span><br><span class="line">    <span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line">    <span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line">    <span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mnist_data</span>():</span><br><span class="line">        <span class="comment"># 定义输入图像的维度</span></span><br><span class="line">        img_rows, img_cols = <span class="number">28</span>, <span class="number">28</span></span><br><span class="line">        <span class="comment"># 加载数据集</span></span><br><span class="line">        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> K.image_data_format() == <span class="string">&#x27;channels_first&#x27;</span>:</span><br><span class="line">            X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">            X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">            input_shape = (<span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">            X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">            input_shape = (img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 数据缩放，将原来的 [0, 255] 缩放至 [0, 1]</span></span><br><span class="line">        X_train = X_train.astype(<span class="string">&#x27;float32&#x27;</span>)/<span class="number">255</span></span><br><span class="line">        X_test = X_test.astype(<span class="string">&#x27;float32&#x27;</span>)/<span class="number">255</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 对原始数据中的目标值进行One-Hot Encoding，使得目标数据更加的稀疏</span></span><br><span class="line">        Y_train = np_utils.to_categorical(Y_train, <span class="number">10</span>)</span><br><span class="line">        Y_test = np_utils.to_categorical(Y_test, <span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 返回结果</span></span><br><span class="line">        <span class="keyword">return</span> (X_train, Y_train), (X_test, Y_test), input_shape</span><br><span class="line">    </span><br><span class="line">    (X_train, Y_train), (X_test, Y_test), input_shape = mnist_data()</span><br></pre></td></tr></table></figure>

<h2 id="3-正确地编码"><a href="#3-正确地编码" class="headerlink" title="3. 正确地编码"></a>3. 正确地编码</h2><p>当处理图片数据的时候，必须要区分想要的编码方式。Keras是一个可以处理多个“后端”的高级库，例如<a target="_blank" rel="noopener" href="https://www.tensorflow.org/">Tensorflow</a>, <a target="_blank" rel="noopener" href="http://deeplearning.net/software/theano/">Theano</a> 和 <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/cognitive-toolkit/">CNTK</a>，首先我们要了解我们所使用的后端是如何编码数据的。在Keras默认使用的TensorFlow后端中，针对图像的处理通常是以“通道优先”或“通道末尾”的方式进行编码的，因此在我们的使用TensorFlow作为后端的时候，编码结果其实是一个张量，其形状为(batch_size, rows, cols, channels)。意味着首先是输入的batch_size，然后输入28行28列的图像维度，最后输入1作为通道数，因为我们使用的是灰度图像数据。</p>
<p>我们可以看看前6张图像具体是什么样子，可以使用如下代码查看：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化数据集中前6张图像</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    %matplotlib inline</span><br><span class="line">    <span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    </span><br><span class="line">    (X_train, y_train), (X_test, y_test) = mnist.load_data()</span><br><span class="line">    </span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">        ax = fig.add_subplot(<span class="number">1</span>, <span class="number">6</span>, i+<span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">        ax.imshow(X_train[i], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">        ax.set_title(<span class="built_in">str</span>(y_train[i]))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://liip.rokka.io/www_inarticle/7cce04/numbers.png"></p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="4-规范化数据"><a href="#4-规范化数据" class="headerlink" title="4. 规范化数据"></a>4. 规范化数据</h2><p>可以看到，在黑色背景中显示了白色数字，每一张图像中的数字都是居中的，而且分辨率都很低——在这个例子中我们使用的是28x28像素。</p>
<p>你可能已经注意到，在上述获取数据的部分，我们对每一张图片除以255来缩放了图像像素，这导致像素值在0和1之间，这对于任何类型的训练都非常有用。每个图像像素值在转换之前都是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用像素值可视化一个数字</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_input</span>(<span class="params">img, ax</span>):</span><br><span class="line">    ax.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    width, height = img.shape</span><br><span class="line">    thresh = img.<span class="built_in">max</span>()/<span class="number">2.5</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(width):</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">            ax.annotate(<span class="built_in">str</span>(<span class="built_in">round</span>(img[x][y], <span class="number">2</span>)),</span><br><span class="line">                        xy=(y, x),</span><br><span class="line">                        horizontalalignment=<span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">                        verticalalignment=<span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">                        color=<span class="string">&#x27;white&#x27;</span> <span class="keyword">if</span> img[x][y] &lt; thresh <span class="keyword">else</span> <span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">visualize_input(X_train[<span class="number">0</span>], ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/keras-mnist-for-ios/pixes-daf69647-717f-499d-aa39-fa83904d7675.png"></p>
<p>可以看到图像中的每个灰度像素都是介于0到255之间的，并且当像素为255时，背景色为白色，像素为0时，背景色为黑色。在这里使用的是<code>mnist.load_data()</code>加载的数据集，此时并没有对图像进行像素缩放，而在我们自定义的数据集加载方法<code>mnist_data()</code>方法中，我们进行了像素的缩放，<code>X_train = X_train.astype(&#39;float32&#39;)/255</code> 。</p>
<h2 id="5-One-Hot-编码"><a href="#5-One-Hot-编码" class="headerlink" title="5. One-Hot 编码"></a>5. One-Hot 编码</h2><p>最初，数据以Y-Vector包含X Vector（像素数据）包含的数值的方式编码。例如，如果图像看起来像7，那么Y-Vector中必定包含数字7。但是这种方式不利于我们在网络结构中直接使用，我们需要进行这种转换，希望将数据的输出映射到网络中的10个输出神经元，此时当相应的数字被识别时，相应的神经元就会触发，从而达到有效的识别。</p>
<p><img src="https://liip.rokka.io/www_inarticle/46a2ef/onehot.png"></p>
<h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><h2 id="6-网络模型化"><a href="#6-网络模型化" class="headerlink" title="6. 网络模型化"></a>6. 网络模型化</h2><p>了解了数据集的基本情况以及进行合理的数据转换后，该是定义卷积神经网络的时候了。这里讲直接使用卷积神经网络中的卷积层和池化层来定义网络，具体实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义网络模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adadelta</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">network</span>():</span><br><span class="line">    model = Sequential()</span><br><span class="line">    input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">    num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(filters=<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=input_shape))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(filters=<span class="number">32</span>, kernel_size=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(Conv2D(filters=<span class="number">32</span>, kernel_size=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">500</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line">    model.add(Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型概述</span></span><br><span class="line">    <span class="built_in">print</span>(model.summary())</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>在模型的定义中，我们以内核大小为3的<a target="_blank" rel="noopener" href="https://keras.io/layers/convolutional/">卷积</a>，这也意味着窗口为3x3像素，输入形状的大小为28x28像素。紧跟着使用了一个池化大小为2的<a target="_blank" rel="noopener" href="https://keras.io/layers/pooling/">池化层</a>，这里的池化大小为2，意味着将会对每一个输入缩减为原来的一般，因此在下一个卷积层中，输入大小为14x14像素。按照此方式重复两次后，最终的卷积输入大小转换为3x3像素。接下来，使用了<a target="_blank" rel="noopener" href="https://keras.io/layers/core/#dropout">Dropout层</a>，将30%的输入单元随机设置为0，以防止训练的过拟合。最后，展平输入层（此例子中为3x3x32&#x3D;288），并将它们连接到一个具有500个输入的密度层。在这些步骤之后，添加了另一个Dropout层，之后连接到最后的密度层，该密度层中包含10个输出单元，这些输出单元对应着我们的目标类别，0到9之间的数字。</p>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 14, 14, 32)        4128      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 7, 7, 32)          4128      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 3, 3, 32)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 3, 3, 32)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 288)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 500)               144500    
_________________________________________________________________
dropout_2 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                5010      
=================================================================
Total params: 158,086
Trainable params: 158,086
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="-2"><a href="#-2" class="headerlink" title=""></a></h2><h2 id="7-训练模型"><a href="#7-训练模型" class="headerlink" title="7. 训练模型"></a>7. 训练模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model = network()</span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=Adadelta(), metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 使用训练数据拟合模型</span></span><br><span class="line">model.fit(X_train, Y_train, batch_size=<span class="number">512</span>, epochs=<span class="number">6</span>, verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line"><span class="comment"># 模型评估分数</span></span><br><span class="line">score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test loss:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>这里使用了<code>categorical_crossentropy</code>作为损失函数，因为我们的目标类别有多个（0至9），Keras库提供了多种<a target="_blank" rel="noopener" href="https://keras.io/optimizers/#usage-of-optimizers">优化器</a>，你可以选择任意一个进行模型训练，并最终找到一个最好的。经过尝试之后，这里选择<a target="_blank" rel="noopener" href="https://keras.io/optimizers/#adadelta"><code>AdaDelta</code></a>作为优化器进行模型训练，当然你也可以尝试AdaDelta的高级版<a target="_blank" rel="noopener" href="https://keras.io/optimizers/#adagrad">AdaGrad</a>。</p>
<p><img src="https://liip.rokka.io/www_inarticle/42b4b8/train.png"></p>
<p>可以看到，经过训练，所得到的模型识别准确率达到了98%，考虑到这里仅仅使用了简单的网络结构，达到这样的准确率已经是非常出色了。在上述截图中，每次迭代的准确性都是在提高，可以说明这里使用的简单结构是合理的，训练得到的模型可以很好地预测输入28x28像素所表示的数字。</p>
<h2 id="8-保存模型"><a href="#8-保存模型" class="headerlink" title="8. 保存模型"></a>8. 保存模型</h2><p>由于我们想要在iOS设备上使用该模型，因此需要将该模型转换为iOS系统能够理解的格式。实际上，微软、Facebook以及亚马逊等企业已经研发出了一套能够在所有深度学习网络格式见转换的协议，以便能够在任何设备上使用的可交换的开放式神经网络交换格式——<a target="_blank" rel="noopener" href="https://onnx.ai/">ONNX</a>。</p>
<p>但是，截止目前，Apple设备上仅仅能够使用的是CoreML格式。为了能够将Keras模型转换为CoreML格式，Apple特意推出来一个非常方便的帮助类库——<a target="_blank" rel="noopener" href="https://apple.github.io/coremltools/generated/coremltools.converters.keras.convert.html">coremltools</a>，这里我们就可以使用该类库来完成工作。该类库能够将scikit-learn、Keras、XGBoost等机器学习类库训练的模型转换为CoreML支持的格式，从而使得模型能够直接在Apple设备上使用。如果你还未安装coremltools类库，可以使用<code>pip install coremltools</code>进行安装，然后再使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">coreml_model = coremltools.converters.keras.convert(model,</span><br><span class="line">                                                        input_names=<span class="string">&quot;image&quot;</span>,</span><br><span class="line">                                                        image_input_names=<span class="string">&#x27;image&#x27;</span>,</span><br><span class="line">                                                        class_labels=[<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;9&#x27;</span>]</span><br><span class="line">                                                        )</span><br></pre></td></tr></table></figure>

<p>在进行模型转换的时候，最重要的参数是class_labels，它定义了模型尝试预测的类数，以及input_names或者image_input_names。通过将它们设置为图像，Xcode会自动识别该模型是关于接收图像并从中预测某些内容，也就是说这些参数是告诉Xcode，该模型是关于那方面的任务。根据应用程序和模型的特定功能，需要研究<a target="_blank" rel="noopener" href="https://apple.github.io/coremltools/generated/coremltools.converters.keras.convert.html">官方文档</a>进一步的了解这些参数的可选值等。</p>
<p>另外还有一些可以定义模型元信息的参数，这些参数可以给模型一个简要的说明，甚至作者、license等，可以让使用者能够方便的查阅模型所针对的特定任务等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑模型元信息</span></span><br><span class="line">coreml_model.author = <span class="string">&#x27;Robin&#x27;</span></span><br><span class="line">coreml_model.license = <span class="string">&#x27;MIT&#x27;</span></span><br><span class="line">coreml_model.short_description = <span class="string">&#x27;MNIST handwriting recognition with a 3 layer network&#x27;</span></span><br><span class="line">coreml_model.input_description[<span class="string">&#x27;image&#x27;</span>] = <span class="string">&#x27;28x28 grayscaled pixel values between 0-1&#x27;</span></span><br><span class="line">coreml_model.save(<span class="string">&#x27;SimpleMnist.mlmodel&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(coreml_model)</span><br></pre></td></tr></table></figure>

<h2 id="9-使用模型预测"><a href="#9-使用模型预测" class="headerlink" title="9. 使用模型预测"></a>9. 使用模型预测</h2><p>在将模型保存为CoreML格式之后，我们可以尝试使用转换后的模型进行一个预测，来确定模型是否工作正常。在这里我们将从MNIST数据集中选择一张图像进行预测验证。</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用CoreML模型预测验证</span></span><br><span class="line"> <span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"> <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> model =  coremltools.models.MLModel(<span class="string">&#x27;SimpleMnist.mlmodel&#x27;</span>)</span><br><span class="line"> im = Image.fromarray((np.reshape(mnist_data()[<span class="number">0</span>][<span class="number">0</span>][<span class="number">12</span>]*<span class="number">255</span>, (<span class="number">28</span>, <span class="number">28</span>))).astype(np.uint8),<span class="string">&quot;L&quot;</span>)</span><br><span class="line"> plt.imshow(im)</span><br><span class="line"> predictions = model.predict(&#123;<span class="string">&#x27;image&#x27;</span>: im&#125;)</span><br><span class="line"> <span class="built_in">print</span>(predictions)</span><br></pre></td></tr></table></figure>

<p>输出结果：</p>
<pre><code>&#123;u&#39;classLabel&#39;: u&#39;3&#39;, 
u&#39;output1&#39;: &#123;u&#39;1&#39;: 0.0, 
                        u&#39;0&#39;: 0.0, 
                        u&#39;3&#39;: 1.0, 
                        u&#39;2&#39;: 0.0, 
                        u&#39;5&#39;: 0.0, 
                        u&#39;4&#39;: 0.0, 
                        u&#39;7&#39;: 0.0, 
                        u&#39;6&#39;: 0.0, 
                        u&#39;9&#39;: 0.0, 
                        u&#39;8&#39;: 0.0
                        &#125;
&#125;
</code></pre>
<p><img src="/images/keras-mnist-for-ios/download-45f07bef-9ca6-4ea6-a674-789607207e9c.png"></p>
<p>可以看到，预测过程和结果均符合预期。接下来是时候在Xcode项目中使用该模型了。</p>
<h1 id="10步完成模型在Xcode项目中的应用"><a href="#10步完成模型在Xcode项目中的应用" class="headerlink" title="10步完成模型在Xcode项目中的应用"></a>10步完成模型在Xcode项目中的应用</h1><p>为了能够让几乎所有人了解机器学习模型文件是如何一步一步在Xcode项目中使用的，这里将会从最为基础的Xcode安装、项目创建等说起，如果你是iOS开发的老鸟，部分内容请自行略过。</p>
<h2 id="1-安装Xcode"><a href="#1-安装Xcode" class="headerlink" title="1. 安装Xcode"></a>1. 安装Xcode</h2><p>对于iOS体系来说，Xcode是开发iOS应用程序必须的工具之一，因此如果你还未安装Xcode，需要安装Xcode，最为简单的方式是在Mac App Store中搜索并安装。如果你已经安装了Xcode，需要确保Xcode的版本至少在9.0或以上。</p>
<h2 id="-3"><a href="#-3" class="headerlink" title=""></a></h2><h2 id="2-创建项目"><a href="#2-创建项目" class="headerlink" title="2. 创建项目"></a>2. 创建项目</h2><p>安装好Xcode之后，开启Xcode，选择iOS平台下的单视图应用，命名项目，这里命名为“MNIST-Demo”，选择一个保存项目文件的位置，创建项目即可。</p>
<p><img src="/images/keras-mnist-for-ios/Untitled-78fa75ca-4376-49e8-b194-bde1699f9be3.png"></p>
<h2 id="3-添加CoreML模型文件"><a href="#3-添加CoreML模型文件" class="headerlink" title="3. 添加CoreML模型文件"></a>3. 添加CoreML模型文件</h2><p>现在，你可以将通过coremltools转换得到的CoreML模型加入到项目中了。最简单的方式是直接拖拽模型文件到项目目录中，如果为了之后更新模型而不用去删掉重新添加，你可以在弹出的选项框中选择“add as Reference”。</p>
<p><img src="/images/keras-mnist-for-ios/add-model-98101cf6-8cf8-4d2a-b58e-30d397c98354.png"></p>
<h2 id="4-删除不需要的视图或者故事版"><a href="#4-删除不需要的视图或者故事版" class="headerlink" title="4. 删除不需要的视图或者故事版"></a>4. 删除不需要的视图或者故事版</h2><p>因为我们仅仅使用相机并显示标签，因此这里会删除掉项目中默认的一些用户界面，也就是项目中的视图控制器和故事面板。当然你也可以选择不删除，直接使用现有的视图和故事面板进行开发，不论选择哪种方式都能达到目的。这里要注意的是，如果选择编码的方式构建应用，再删除了主故事面板文件后，需要在项目的TARGETS中同步删除”Main Interface”的默认设置。</p>
<p><img src="/images/keras-mnist-for-ios/ScreenShot2018-11-22at10-9150b677-f351-4732-bfb6-d74019527380.32.46AM.png"></p>
<h2 id="5-程序化创建根视图控制器"><a href="#5-程序化创建根视图控制器" class="headerlink" title="5. 程序化创建根视图控制器"></a>5. 程序化创建根视图控制器</h2><p>接下来我们将使用代码的方式，重新制定应用程序的根视图。具体如下：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过编码的方式指定根视图控制器</span></span><br><span class="line"><span class="keyword">func</span> <span class="title function_">application</span>(<span class="keyword">_</span> <span class="params">application</span>: <span class="type">UIApplication</span>, <span class="params">didFinishLaunchingWithOptions</span> <span class="params">launchOptions</span>: [<span class="params">UIApplicationLaunchOptionsKey</span>: <span class="keyword">Any</span>]<span class="operator">?</span>) -&gt; <span class="type">Bool</span> &#123;</span><br><span class="line">     <span class="comment">// 创建窗口</span></span><br><span class="line">     window <span class="operator">=</span> <span class="type">UIWindow</span>()</span><br><span class="line">     window<span class="operator">?</span>.makeKeyAndVisible()</span><br><span class="line">        </span><br><span class="line">     <span class="comment">// 指定根视图控制器</span></span><br><span class="line">     <span class="keyword">let</span> vc <span class="operator">=</span> <span class="type">ViewController</span>()</span><br><span class="line">     window<span class="operator">?</span>.rootViewController <span class="operator">=</span> vc</span><br><span class="line">        </span><br><span class="line">     <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="6-构建视图控制器细节"><a href="#6-构建视图控制器细节" class="headerlink" title="6. 构建视图控制器细节"></a>6. 构建视图控制器细节</h2><p>接下来就是构建视图控制器的详细内容细节了。我们需要以下可交互的元素组件，例如按钮，也需要作为展示结果或者状态的标签等，另外重要的是，由于需要使用相机，因此AVFoundation类库是必须要添加的，该库用来访问和控制iOS设备上的相机，还需要Vision库，该库是iOS推出的用于计算机视觉相关任务的工具库，能够很好的和CoreML模型之间进行交互等。</p>
<p>具体的代码细节，这里不再累述，完成之后的代码如下：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义视图控制器</span></span><br><span class="line"><span class="keyword">import</span> UIKit</span><br><span class="line"><span class="keyword">import</span> AVFoundation</span><br><span class="line"><span class="keyword">import</span> Vision</span><br><span class="line"></span><br><span class="line"><span class="comment">// 由于要使用到相机设备进行视频流的输入，因此这里要继承AVCaptureVideoDataOutputSampleBufferDelegate协议</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ViewController</span>: <span class="title class_">UIViewController</span>, <span class="title class_">AVCaptureVideoDataOutputSampleBufferDelegate</span> &#123;</span><br><span class="line">    <span class="comment">// 创建一个文本标签用来显示识别结果</span></span><br><span class="line">    <span class="keyword">let</span> label: <span class="type">UILabel</span> <span class="operator">=</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> label <span class="operator">=</span> <span class="type">UILabel</span>()</span><br><span class="line">        label.textColor <span class="operator">=</span> .white</span><br><span class="line">        label.translatesAutoresizingMaskIntoConstraints <span class="operator">=</span> <span class="literal">false</span></span><br><span class="line">        label.text <span class="operator">=</span> <span class="string">&quot;Label&quot;</span></span><br><span class="line">        label.font <span class="operator">=</span> label.font.withSize(<span class="number">40</span>)</span><br><span class="line">        <span class="keyword">return</span> label</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="keyword">func</span> <span class="title function_">viewDidLoad</span>() &#123;</span><br><span class="line">        <span class="comment">// 调用相机设备设置方法、文本标签设置方法</span></span><br><span class="line">        <span class="keyword">super</span>.viewDidLoad()       </span><br><span class="line">        setupCaptureSession()</span><br><span class="line">        view.addSubview(label)</span><br><span class="line">        setupLabel()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置相机设备session</span></span><br><span class="line">    <span class="keyword">func</span> <span class="title function_">setupCaptureSession</span>() &#123;</span><br><span class="line">        <span class="comment">// 创建一个新的捕获session</span></span><br><span class="line">        <span class="keyword">let</span> captureSession <span class="operator">=</span> <span class="type">AVCaptureSession</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 查找可用的相机设备</span></span><br><span class="line">        <span class="keyword">let</span> availableDevices <span class="operator">=</span> <span class="type">AVCaptureDevice</span>.<span class="type">DiscoverySession</span>(deviceTypes: [.builtInWideAngleCamera], mediaType: <span class="type">AVMediaType</span>.video, position: .back).devices</span><br><span class="line"></span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            <span class="comment">// 选择首个设备并设置为输入源</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">let</span> captureDevice <span class="operator">=</span> availableDevices.first &#123;</span><br><span class="line">                captureSession.addInput(<span class="keyword">try</span> <span class="type">AVCaptureDeviceInput</span>(device: captureDevice))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">            <span class="comment">// 如果未找到相机设备，则打印错误信息</span></span><br><span class="line">            <span class="built_in">print</span>(error.localizedDescription)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将视频输出设置到屏幕并将输出添加到我们的捕获会话</span></span><br><span class="line">        <span class="keyword">let</span> captureOutput <span class="operator">=</span> <span class="type">AVCaptureVideoDataOutput</span>()</span><br><span class="line">        captureSession.addOutput(captureOutput)</span><br><span class="line">        <span class="keyword">let</span> previewLayer <span class="operator">=</span> <span class="type">AVCaptureVideoPreviewLayer</span>(session: captureSession)</span><br><span class="line">        previewLayer.frame <span class="operator">=</span> view.frame</span><br><span class="line">        view.layer.addSublayer(previewLayer)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 缓冲视频并启动捕获会话</span></span><br><span class="line">        captureOutput.setSampleBufferDelegate(<span class="keyword">self</span>, queue: <span class="type">DispatchQueue</span>(label: <span class="string">&quot;videoQueue&quot;</span>))</span><br><span class="line">        captureSession.startRunning()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">func</span> <span class="title function_">captureOutput</span>(<span class="keyword">_</span> <span class="params">output</span>: <span class="type">AVCaptureOutput</span>, <span class="params">didOutput</span> <span class="params">sampleBuffer</span>: <span class="type">CMSampleBuffer</span>, <span class="params">from</span> <span class="params">connection</span>: <span class="type">AVCaptureConnection</span>) &#123;</span><br><span class="line">        <span class="comment">// 加载Core ML 模型</span></span><br><span class="line">        <span class="keyword">guard</span> <span class="keyword">let</span> model <span class="operator">=</span> <span class="keyword">try?</span> <span class="type">VNCoreMLModel</span>(for: <span class="type">SimpleMnist</span>().model) <span class="keyword">else</span> &#123; <span class="keyword">return</span> &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用Core ML运行推理</span></span><br><span class="line">        <span class="keyword">let</span> request <span class="operator">=</span> <span class="type">VNCoreMLRequest</span>(model: model) &#123; (finishedRequest, error) <span class="keyword">in</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 捕获推理结果</span></span><br><span class="line">            <span class="keyword">guard</span> <span class="keyword">let</span> results <span class="operator">=</span> finishedRequest.results <span class="keyword">as?</span> [<span class="type">VNClassificationObservation</span>] <span class="keyword">else</span> &#123; <span class="keyword">return</span> &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 捕获得分最高的推理结果</span></span><br><span class="line">            <span class="keyword">guard</span> <span class="keyword">let</span> <span class="type">Observation</span> <span class="operator">=</span> results.first <span class="keyword">else</span> &#123; <span class="keyword">return</span> &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 构建最终显示的文本格式</span></span><br><span class="line">            <span class="keyword">let</span> predclass <span class="operator">=</span> <span class="string">&quot;<span class="subst">\(Observation.identifier)</span>&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 显示在文本标签内</span></span><br><span class="line">            <span class="type">DispatchQueue</span>.main.async(execute: &#123;</span><br><span class="line">                <span class="keyword">self</span>.label.text <span class="operator">=</span> <span class="string">&quot;<span class="subst">\(predclass)</span> &quot;</span></span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 创建一个核心视频像素缓冲区，它是一个图像缓冲区，用于保存主存储器中的像素生成帧，</span></span><br><span class="line">                <span class="comment">// 压缩或解压缩视频或使用核心图像的应用程序都可以使用核心视频像素缓冲区</span></span><br><span class="line">        <span class="keyword">guard</span> <span class="keyword">let</span> pixelBuffer: <span class="type">CVPixelBuffer</span> <span class="operator">=</span> <span class="type">CMSampleBufferGetImageBuffer</span>(sampleBuffer) <span class="keyword">else</span> &#123; <span class="keyword">return</span> &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行请求</span></span><br><span class="line">        <span class="keyword">try?</span> <span class="type">VNImageRequestHandler</span>(cvPixelBuffer: pixelBuffer, options: [:]).perform([request])</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">func</span> <span class="title function_">setupLabel</span>() &#123;</span><br><span class="line">        label.centerXAnchor.constraint(equalTo: view.centerXAnchor).isActive <span class="operator">=</span> <span class="literal">true</span></span><br><span class="line">        label.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: <span class="operator">-</span><span class="number">50</span>).isActive <span class="operator">=</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果你直接使用上述代码，请记得修改模型的名称。</p>
</blockquote>
<p><img src="/images/keras-mnist-for-ios/Untitled-503351b4-b11a-4e7b-a7ad-de4017cbac28.png"></p>
<h2 id="6-添加隐私说明信息"><a href="#6-添加隐私说明信息" class="headerlink" title="6. 添加隐私说明信息"></a>6. 添加隐私说明信息</h2><p>由于我们要使用相机设备进行视频数据流的获取，因此需要在Xcode工程项目中的info.plist文件中添加相应的权限申请说明“<em>Privacy - Camera Usage Description</em>”，并附带相应的说明性文字：</p>
<p><img src="/images/keras-mnist-for-ios/Untitled-8e6fa826-e368-47d0-8256-588a136119db.png"></p>
<h2 id="7-加入苹果开发者计划"><a href="#7-加入苹果开发者计划" class="headerlink" title="7. 加入苹果开发者计划"></a>7. 加入苹果开发者计划</h2><p>为了能够让该应用程序运行在你的手机设备上，你可能需要注册<a target="_blank" rel="noopener" href="https://developer.apple.com/programs/enroll/">苹果的开发者计划</a>。当然如果你不想为了运行项目而花费金钱，你也可以按照<a target="_blank" rel="noopener" href="https://9to5mac.com/2016/03/27/how-to-create-free-apple-developer-account-sideload-apps/">此教程</a>注册免费的账户。</p>
<h2 id="8-在iPhone设备上发布应用"><a href="#8-在iPhone设备上发布应用" class="headerlink" title="8. 在iPhone设备上发布应用"></a>8. 在iPhone设备上发布应用</h2><p>一切准备好之后，你就可以将该应用程序发布到你的手机设备上了。你可以按照如下图所示的方式发布项目，也可以直接在Xcode中选定目标设备，然后使用快捷键CMD+R的方式构建：</p>
<p><img src="/images/keras-mnist-for-ios/Untitled-1a74e4bf-8c84-4e49-95f2-4b46f8f4102f.png"></p>
<h2 id="9-使用应用程序"><a href="#9-使用应用程序" class="headerlink" title="9. 使用应用程序"></a>9. 使用应用程序</h2><p>经过上述各种设置和编码之后，终于可以在设备上运行我们的应用程序了。如果一切正常，首次应用程序启动的时候，会询问你是否允许应用程序访问设备的相机，这里需要允许，否则我们的应用程序则无法正常工作。</p>
<p>另外，我们这里所训练的模型以及制作的应用程序，没有进行详细的设计和优化，在识别的过程中，可能会遇到识别不出来以及识别错误的情况，如果需要将此功能应用在你的产品中，需要严格重新审查你所拥有的数据，以及模型的训练，app的使用等，以免出现不可预知的错误等问题。</p>
<p><img src="https://liip.rokka.io/www_inarticle/812493/output.gif"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过这篇文章，希望能够让你了解如何使用Keras训练所需要的模型，以及如何将其应用在iOS平台下的应用程序中，虽然介绍的不够深入，但是希望能够带给你继续深入理解Keras、了解Core ML的欲望，早日在你的应用程序中实现AI的能力，为你的应用程序增添色彩。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:33:12.104Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T06:33:12.104Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">23 分钟读完 (大约3452个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2018-08-03-ml-normal-methods/">机器学习问题的通用方法</a></h1><div class="content"><p>一位数据科学家平均每天处理大量数据，有人说，超过60-70％的时间花在了数据采集、数据清理、数据整理上，使得机器学习模型可以应用于这些数据。本文重点介绍第二部分，即应用机器学习模型，包括预处理步骤。这篇文章中讨论的流水线是我参与过的一百多次机器学习竞赛的结果。必须指出，这里的讨论虽然普通，但非常有用，也存在非常复杂的方法，可供专业人员练习。</p>
<p>我们将在这里使用python！</p>
<h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>在应用机器学习模型之前，必须将数据转换为表格形式。整个过程是最耗时且最困难的过程，如下图所示。</p>
<p><img src="/images/ml-normal/1.png"></p>
<p>然后是机器学习模型应用于表格数据，表格数据是在机器学习或数据挖掘中表示数据的最常用方式。我们有一个数据表，包含不同数据样本（或X和标签y）的行。标签可以是单列或多列，具体取决于问题的类型。我们将用X表示数据，用y表示标签。</p>
<h1 id="标签的类型"><a href="#标签的类型" class="headerlink" title="标签的类型"></a>标签的类型</h1><p>标签定义了问题，可以是不同的类型，如：</p>
<ul>
<li>单列，二元值（分类问题，一个样本只属于一个类，只有两个类）</li>
<li>单列，实数值（回归问题，仅预测一个值）</li>
<li>多列，二元值（分类问题，一个样本属于一个类，但有两个以上的类）</li>
<li>多列，实数值（回归问题，多值预测）</li>
<li>多标签（分类问题，一个样本可以属于几个类）</li>
</ul>
<h1 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h1><p>对于任何类型的机器学习问题，我们必须确定将如何评估我们的结果，要评估的指标或目标是什么？例如，如果存在倾斜的二分类问题，我们通常选择受试者工作特征曲线下的面积（ROCAUC或简称AUC）。在多标签或多分类问题的情况下，我们通常选择分类交叉熵或多分类对数损失，在回归问题的情况下选择均方误差。</p>
<p>我不会详细讨论不同的评估指标，我们可以有许多不同的类型，具体取决于问题本身。</p>
<h1 id="机器学习库"><a href="#机器学习库" class="headerlink" title="机器学习库"></a>机器学习库</h1><p>要开始使用机器学习库，首先安装基本的和最重要的库，例如numpy和scipy。</p>
<p>查看和执行数据操作：pandas（<a target="_blank" rel="noopener" href="http://pandas.pydata.org/">http://pandas.pydata.org/</a>）<br>对于各种机器学习模型：scikit-learn（<a target="_blank" rel="noopener" href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a>）<br>最好的梯度提升库：xgboost（<a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost">https://github.com/dmlc/xgboost</a>）<br>对于神经网络：keras（<a target="_blank" rel="noopener" href="http://keras.io/">http://keras.io/</a>）<br>可视化数据：matplotlib（<a target="_blank" rel="noopener" href="http://matplotlib.org/">http://matplotlib.org/</a>）<br>监视进度：tqdm（<a target="_blank" rel="noopener" href="https://pypi.python.org/pypi/tqdm">https://pypi.python.org/pypi/tqdm</a>）</p>
<h1 id="机器学习框架"><a href="#机器学习框架" class="headerlink" title="机器学习框架"></a>机器学习框架</h1><p>2015年，我提出了一个自动机器学习框架，该框架目前仍在开发中，将于近期发布。在这篇文章中，相同的（基础）框架如下图所示：</p>
<p><img src="/images/ml-normal/2.png"></p>
<p>本图来自：A.Thakur和A.Krohn-Grimberghe，AutoCompete：机器学习竞赛框架，AutoMLWorkshop，2015年机器学习国际会议</p>
<p>在上面显示的框架中，粉红色的线代表最常用的路径。在我们提取并将数据缩减为表格格式后，我们可以继续构建机器学习模型。</p>
<p>第一步是确定问题，这可以通过查看标签来完成。必须知道问题是二分类、多分类、多标签分类还是回归问题。在我们确定问题后，我们将数据分成两个不同的部分，一个训练集和一个验证集，如下图所示。</p>
<p><img src="/images/ml-normal/3.png"></p>
<p>数据分解为训练集和验证集“必须”考虑标签类型。如果出现任何类型的分类问题，请使用分层分割。在python中，你可以很容易地使用scikit-learn。</p>
<p><img src="/images/ml-normal/4.png"></p>
<p>在回归任务的情况下，简单的K-Fold分割就足够了。然而，有些复杂的方法往往需要训练集和验证集保持相同的标签分布，这个问题将留给读者作为练习。</p>
<p><img src="/images/ml-normal/5.png"></p>
<p>上述示例中我已经选择全部数据的10％作为eval_size或验证集的大小，此值可以根据它们所具有的数据大小进行选择。</p>
<p>数据拆分完成后，请保留此数据不要动它。必须保存在训练集上应用的任何操作，然后将其应用于验证集。在任何情况下，验证集都不应该与培训集一起使用，这样做会产生非常好的评估分数并让用户感到满意，但是会构建一个严重过拟合的无用模型。</p>
<p>下一步是识别数据中的不同变量。我们处理的变量通常有三种类型，即数字变量、分类变量和包含文本的变量。让我们以流行的泰坦尼克号数据集（<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/titanic/data%EF%BC%89%E4%B8%BA%E4%BE%8B%E3%80%82">https://www.kaggle.com/c/titanic/data）为例。</a></p>
<p><img src="/images/ml-normal/6.png"></p>
<p>在这里，survival就是标签，我们已经将标签从前一步中的训练数据中分离出来了。变量pclass、sex、embarke具有不同的级别，因此它们是分类变量。像age、sibsp、parch等变量是数值变量。name是一个包含文本数据的变量，但我不认为它是预测生存的有用变量。</p>
<p>首先对于数值变量，这些变量不需要任何类型的处理，因此我们可以直接对这些变量应用规范化和机器学习模型。</p>
<p>有两种方法可以处理分类数据：</p>
<ul>
<li>将分类数据转换为标签</li>
</ul>
<p><img src="/images/ml-normal/7.png"></p>
<ul>
<li>将标签转换为二元变量（one-hot编码）</li>
</ul>
<p><img src="/images/ml-normal/8.png"></p>
<p>请记住先使用LabelEncoder将类别转换为数字，然后再应用OneHotEncoder。</p>
<p>因为泰坦尼克号的数据没有文本变量的好例子，所以让我们制定处理文本变量的一般规则。我们可以将所有文本变量合并为一个，然后使用一些对文本数据起作用的算法并将其转换为数字。</p>
<p>文本变量可以如下连接在一起：</p>
<p><img src="/images/ml-normal/9.png"></p>
<p>我们可以在变量上使用CountVectorizer或TfidfVectorizer：</p>
<p><img src="/images/ml-normal/10.png"></p>
<p>或</p>
<p><img src="/images/ml-normal/11.png"></p>
<p>TfidfVectorizer大多数时候比CountVectorizer性能都要好， TfidfVectorizer使用以下参数在很多情况下都有效。</p>
<p><img src="/images/ml-normal/12.png"></p>
<p>如果您只在训练集上应用这些vectorizer，请确保将其转储到磁盘中，以便稍后在验证集上使用它。</p>
<p><img src="/images/ml-normal/13.png"></p>
<p>接下来，我们来到stacker模块，stacker模块不是模型堆垛器，而是特征堆垛器。上述处理步骤之后的不同特征可以使用堆叠器模块进行组合。</p>
<p><img src="/images/ml-normal/14.png"></p>
<p>在通过使用numpy hstack或sparsehstack 进行进一步处理之前，您可以水平堆叠所有特征，具体取决于您是否拥有稠密或稀疏的特征。</p>
<p><img src="/images/ml-normal/15.png"></p>
<p>如果还有其他处理步骤如PCA或特征选择（我们将在本文的稍后部分讲解分解和特征选择），也可以通过FeatureUnion模块实现。</p>
<p><img src="/images/ml-normal/16.png"></p>
<p>一旦将这些特征堆叠在一起，我们可以开始应用机器学习模型。在这个阶段，你应该选择的模型应该集成基于树的模型。这些模型包括：</p>
<ul>
<li>RandomForestClassifier</li>
<li>RandomForestRegressor</li>
<li>ExtraTreesClassifier</li>
<li>ExtraTreesRegressor</li>
<li>XGBClassifier</li>
<li>XGBRegressor</li>
</ul>
<p>我们不能将线性模型应用于上述特征，因为它们没有归一化。要使用线性模型，可以使用scikit-learn中的Normalizer或StandardScaler。</p>
<p>这些归一化方法仅适用于稠密特征，如果应用于稀疏特征则不会给出非常好的结果。但可以在不使用均值的情况下在稀疏矩阵上应用StandardScaler（参数：with_mean&#x3D; False）。</p>
<p>如果上述步骤给出了一个“好”的模型，我们可以去优化超参数，如果没有，我们需要继续下面的步骤并改进我们的模型。</p>
<p><img src="/images/ml-normal/17.png"></p>
<p>为了简单起见，我们将忽略LDA和QDA转换。对于高维数据，通常使用PCA来分解数据。对于图片以10-15个component开始，并且只要结果质量显着提高，就增加此数量。对于其他类型的数据，我们最初选择了50-60个component（只要我们能够处理得了数值数据，我们就倾向于避免PCA）。</p>
<p><img src="/images/ml-normal/18.png"></p>
<p>对于文本数据，在将文本转换为稀疏矩阵后，进行奇异值分解（SVD）。可以在scikit-learn中找到称为TruncatedSVD的SVD变体。</p>
<p><img src="/images/ml-normal/19.png"></p>
<p>通常用于TF-IDF或计数的SVD component的数量在120-200之间。以上任何数字都可能会提高性能，但不会实质性降低计算能力。</p>
<p>在进一步评估模型的性能之后，我们转向数据集的缩放，以便我们也可以评估线性模型。特征被归一化或缩放后可以被发送到机器学习模型或特征选择模块。</p>
<p><img src="/images/ml-normal/20.png"></p>
<p>有多种方法可以实现特征选择。最常见的方式之一是贪婪特征选择（向前或向后）。在贪婪特征选择中，我们选择一个特征，训练一个模型并根据固定评估指标评估模型的性能，我们一个接一个不断添加和删除特征，并在每一步记录模型的性能，最后我们选择评估得分最高的特征。以AUC作为评估指标的贪婪特征选择的一个实现可以在这里找到：https：&#x2F;&#x2F;github.com&#x2F;abhishekkrthakur&#x2F;greedyFeatureSelection。必须指出的是，这种实现并不完美，必须根据要求进行修改。</p>
<p>其他更快的特征选择方法包括从模型中选择最佳特征。我们既可以查看logit模型的系数，也可以训练一个随机森林来选择最佳特征，然后在其他机器学习模型中使用这些特征。</p>
<p><img src="/images/ml-normal/21.png"></p>
<p>请记住，要保持较少的estimator和最少的超参数优化，以免过拟合。</p>
<p>使用梯度提升(GradientBoosting )也可以实现特征选择。我们在scikit-learn中推荐使用xgboost而不是GBM的实现，因为xgboost更快更灵活。</p>
<p><img src="/images/ml-normal/22.png"></p>
<p>我们也可以使用RandomForestClassifier &#x2F; RandomForestRegressor和xgboost来进行稀疏数据集的特征选择。</p>
<p>从正稀疏数据集中选择特征的另一种流行方法是基于chi-2的特征选择，我们在scikit-learn中实现了这一功能。</p>
<p><img src="/images/ml-normal/23.png"></p>
<p>在这里，我们使用chi2和SelectKBest从数据中选择20个特征。这是我们想要优化以提高机器学习模型结果的超参数。</p>
<p>不要忘记导出在所有步骤中使用的任何种类的transformer，它们将被用于在验证集上的评估性能。</p>
<p>下一个（或中间）的主要步骤是模型选择+超参数优化。</p>
<p><img src="/images/ml-normal/24.png"></p>
<p>我们通常在选择机器学习模型的过程中使用以下算法：</p>
<ul>
<li><p><strong>分类</strong></p>
<ul>
<li>Random Forest</li>
<li>GBM</li>
<li>Logistic Regression</li>
<li>Naive Bayes</li>
<li>Support Vector Machines</li>
<li>k-Nearest Neighbors</li>
</ul>
</li>
<li><p><strong>回归</strong></p>
<ul>
<li>Random Forest</li>
<li>GBM</li>
<li>Linear Regression</li>
<li>Ridge</li>
<li>Lasso</li>
<li>SVR</li>
</ul>
</li>
</ul>
<p>我们应该优化哪些参数？如何选择趋近最佳的参数？这些是大多数人想到得到的几个问题。如果没有大量数据集上不同模型+参数的经验，就无法得到这些问题的答案，可能也有有经验的人不愿意分享他们的秘密。幸运的是，我也有相当多的经验，同时我愿意分享一些东西。</p>
<p>让我们分解超参数，使模型更智能：</p>
<p><img src="/images/ml-normal/25.png"></p>
<p>RS* &#x3D;不能说完全适当的值，随机搜索这些超参数。</p>
<p>严格地说我的观点是，上述模型将超越其他模型，我们不需要评估任何其他模型。</p>
<p>再次记住保存transformer：</p>
<p><img src="/images/ml-normal/26.png"></p>
<p>并将它们分别应用于验证集：</p>
<p><img src="/images/ml-normal/27.png"></p>
<p>上述规则和框架在我处理的大多数数据集中都表现得非常好。当然，对于非常复杂的任务也可能是失败的。没有什么是完美的，我们继续改进我们学到的东西，就像机器学习一样。</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/04/30/2018-07-24-speech-recognation-mfcc/"><img class="fill" src="/images/speech-recognition/audio_draw.png" alt="基于MFCC的语音数据特征提取概述"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:33:12.101Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T06:33:12.102Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">39 分钟读完 (大约5786个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2018-07-24-speech-recognation-mfcc/">基于MFCC的语音数据特征提取概述</a></h1><div class="content"><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>语音是人类之间沟通交流的最直接也是最快捷方便的一种手段，而实现人类与计算机之间畅通无阻的语音交流，一直是人类追求的一个梦想。</p>
<p>伴随着移动智能设备的普及，各家移动设备的厂家也开始在自家的设备上集成了语音识别系统，像Apple Siri、Microsoft Cortana、Google Now等语音助手的出现，使得人们在使用移动设备的同时，也能够进行语音交流，极大的方便了人们的生活。但是此类助手也存在一些尴尬的瞬间，例如在一些工作场合或者聚会的场合，某人的一句“Hey Siri”就可能唤醒多台苹果设备，使用者难免尴尬困惑。</p>
<p>而此类予语音助手背后，均是一种被称作“闻声识人”的计算机技术，称为<strong>语音识别</strong>。语音识别技术属于生物认证技术，而其中的说话人识别（speaker recognize，SR）是其中的一种，该技术通常也被称为<strong>声纹识别</strong>技术，该技术是一项通过语音波形中反映说话人生理特征和行为特征的一组语音参数，自动识别说话人身份的技术。其核心是通过预先录入说话人的声音样本，提取出说话人独一无二的语音特征并存入数据库，应用的时候将待验证的语音进行特征提取并与数据库中的特征进行匹配，以确定说话人的身份。</p>
<h2 id="1-1-什么是声纹？"><a href="#1-1-什么是声纹？" class="headerlink" title="1.1 什么是声纹？"></a>1.1 什么是声纹？</h2><p>声纹（voiceprint）是用电声学仪器显示的携带者言语信息的声波频谱，是由波长、频率以及强度等百余种特征维度组成的生物特征，具有稳定性、可测量性以及唯一性等特点。</p>
<ul>
<li>人类语言的产生是由人体语言中枢与发生器官之间进行的一个复杂的生物物理反应过程。发声器官如舌头、牙齿、喉咙、肺、鼻子在尺寸和形态上因人而异，所有任何两个人的声波图谱都有一定的差异性。</li>
<li>每个人的语音声学特征既有相对稳定性，又有个体差异性。这种差异可能来自生理、病理、心理、模拟、伪装等，也可能会周围环境的干扰相关。</li>
<li>由于每个人的发生器官都有其独特性，因此在一般情况下，人们仍然能区别不同的人的声音或者判断是否是同一个人的声音。</li>
</ul>
<p>声纹不像图像那样的直观，在实际的分析中，可以通过波形图和语谱图进行绘制展现，例如下图是一段从1到10的读数语音文件对应的波形图和语谱图（上部分为声音波形图，下部分为声音语谱图）：</p>
<p><img src="/images/speech-recognition/audio_draw.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wave</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fw = wave.<span class="built_in">open</span>(<span class="string">&#x27;test.wav&#x27;</span>,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">soundInfo = fw.readframes(-<span class="number">1</span>)</span><br><span class="line">soundInfo = np.fromstring(soundInfo,np.int16)</span><br><span class="line">f = fw.getframerate()</span><br><span class="line">fw.close()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.plot(soundInfo)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Amplitude&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Wave from and spectrogram of test.wav&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.specgram(soundInfo,Fs = f, scale_by_freq = <span class="literal">True</span>, sides = <span class="string">&#x27;default&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;time(seconds)&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>语谱图更简单的绘制方法，可参考 <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.signal.spectrogram.html">scipy.signal.spectrogram</a>。</li>
<li>语谱图绘制的原理，可参考 <a target="_blank" rel="noopener" href="http://www.frank-zalkow.de/en/code-snippets/create-audio-spectrograms-with-python.html?i=1">Create audio spectrograms with Python</a>。</li>
</ul>
<p>与其他的生物认证技术如指纹识别、人脸识别、虹膜识别等相同，声纹识别具有不会遗忘、无需记忆和使用方便等优点。在生物认证技术领域，说话人识别技术以其独特的方便性、经济性和准确性收到人们的广泛关注，并日益成为人们日常生活和工作中重要且普及的安全认证方式。</p>
<p>但是，说话人识别有着其他生物认证技术所不具有的优势：</p>
<ul>
<li>用户接受度高：以声音作为识别特征，因其非接触性和自然醒，用户易接受。用户不用刻意的用手指触摸相应的传感器上，也不用将眼睛凑向摄像头，只需要简单的说一两句话即可完成识别认证。</li>
<li>设备成本低：对输入设备如麦克风，摄像头等没有特别的要求，特征提取，模型训练和匹配只需要普通的计算机即可完成。</li>
<li>其他生物认证特征技术各有其劣势：指纹识别需要特殊的传感器芯片，虹膜识别精确度较高，但是设备较为昂贵。</li>
<li>在远程应用和移动互联网环境下优势明显：通过电话、移动设备进行身份认证，声音是最具优势的生物特征，语音控制也逐渐成为流行的交互形式，以声音为特征的身份鉴别技术也越发重要。</li>
</ul>
<h2 id="1-2-声纹识别技术的历史"><a href="#1-2-声纹识别技术的历史" class="headerlink" title="1.2 声纹识别技术的历史"></a>1.2 声纹识别技术的历史</h2><p>声纹识别技术的研究始于20世纪30年代，早期的工作主要集中于人耳听辨实验和探讨听音识别的可能性方面。随着研究手段和计算机技术的发展，研究工作逐渐脱离了单纯的人耳听辨，使得通过机器自动识别人的声音称为可能。在这个过程中也出现了很多不同的计算机技术，从早期的模板匹配到最新的深度学习技术，均在不断的刷新着语音识别技术手段。整体来看，声纹识别技术的发展经历了七个技术演进之路，详见下图（下图来自speakin）：</p>
<p><img src="/images/speech-recognition/voiceprint_history.jpg"></p>
<h2 id="1-3-声纹识别的种类"><a href="#1-3-声纹识别的种类" class="headerlink" title="1.3 声纹识别的种类"></a>1.3 声纹识别的种类</h2><p>声纹识别根据实际应用的范畴可以分为 1:1识别 和 1:N识别两种：</p>
<ul>
<li><p>1:1识别：指确定待识别的一段语音是否来自其所声明的目标说话人，即确认目标说话人是目标说话人的过程。通常应用于电子支付、智能硬件、银行证券交易等。1:1识别有两个系统的性能评价参量，分别为</p>
<ul>
<li>错误接受率(False Acceptation Rate, FAR)：将非目标说话人判别为目标说话人造成的错误率</li>
<li>错误拒绝率(False Rejection Rate, FRR)：将目标说话人误识成非目标说话人造成的错误率</li>
</ul>
<p>  对安全性要求越高，则设定阈值越高，此时接受目标说话人的条件越严格，即FRR越高，FAR越低；对用户体验要求越高，则设定阈值越低，此时接受目标说话人的条件越宽松，即FAR越高，FRR越低。在声纹系统中，可以通过设定不同的阈值来平衡FAR和FRR。</p>
</li>
<li><p>1:N识别：指判定待识别语音属于目标说话人模型集合中的哪一个人，即在N个人中找到目标说话人的过程。通常应用于公安司法、军队国防等。</p>
</li>
</ul>
<h1 id="2-语音的特征提取方法概述"><a href="#2-语音的特征提取方法概述" class="headerlink" title="2. 语音的特征提取方法概述"></a>2. 语音的特征提取方法概述</h1><p>语音是一种数字信号，其数字⾳频的采样率为44100Hz（根据乃奎斯特取样定理得出的结果，在模拟讯号数字化的过程中，如果保证取样频率大于模拟讯号最高频率的2倍，就能100%精确地再还原出原始的模拟讯息。音频的最高频率为20kHz，所以取样率至少应该大于40kHz，为了留一点安全系数，再考虑到工程上的习惯，最终选择了44.1kHz这个数值）。通常情况下使用傅里叶变换将信号在时域与频域之间进行转换，而频谱图可以显示傅里叶变换后的振幅与时间和频率的对应关系。</p>
<h2 id="2-1-特征提取方法"><a href="#2-1-特征提取方法" class="headerlink" title="2.1 特征提取方法"></a>2.1 特征提取方法</h2><p>对于语音识别系统而言，所提取的特征参数需要能够反映特定发信的信息，在说话人无关的系统中，更要求参数能够反映不同说话人相同发音的信息，要求说话人的特征参数要能够代表特定的说话人，能够区分不同说话人相同语音之间的差异，最好能够做到与具体的发音内容无关，也称为文本无关。</p>
<p>在语音特征参数提取技术的发展历程中，<a target="_blank" rel="noopener" href="https://blog.csdn.net/qingkongyeyue/article/details/52149839">线性预测编码（Linear Predictive Coding, LPC）</a>被广泛应用于语音特征参数的提取，其中包括LPC系数、反射LPC系数、面积函数和LPC倒谱系数，能够很好的反映语音的声道特征，但是却对语音的其他特征无能为力。</p>
<p> 不同于LPC等通过对人的发声机理进行研究而得到的声学特征，Mel倒谱系数MFCC是受人的听觉系统研究成果推出而导出的声学特征。根据人耳听觉机理的研究发现，人耳对不同频率的声波有不同的听觉灵敏度。从200Hz到5000Hz的语音信号对语音的清晰度影响最大。人们从低频到高频这一段频带内按临界带宽的大小由密到疏安排一组带通滤波器，对输入信号进行滤波。将每个带通滤波器输出的信号能量作为信号的基本特征，对此特征经过进一步处理后就可以作为语音的输入特征。由于这种特征不依赖于信号的性质，对输入信号不做任何的假设和限制，又利用了听觉模型的研究成果。因此，这种参数比基于声道模型的LPC相比具有更好的鲁棒性，更符合人耳的听觉特性，而且当信噪比降低时仍然具有较好的识别性能。</p>
<p> MFCC（MeI-Freguency CeptraI Coefficients）是需要语音特征参数提取方法之一，因其独特的基于倒谱的提取方式，更加的符合人类的听觉原理，因而也是最为普遍、最有效的语音特征提取算法。MFCC是在Mel标度频率域提取出来的倒谱系数，Mel标度描述了人耳对频率感知的非线性特性。</p>
<h2 id="2-2-MFCC语音特征提取"><a href="#2-2-MFCC语音特征提取" class="headerlink" title="2.2 MFCC语音特征提取"></a>2.2 MFCC语音特征提取</h2><p>MFCC 语音特征的提取过程，如下图：</p>
<p><img src="/images/speech-recognition/mfcc-process.png"></p>
<p>需要对语音信号进行预加重、分帧、加窗等等处理，而这些处理的方式均是为了能够最大化语音信号的某些信息，以达到最好特征参数的提取。</p>
<h3 id="2-2-1-预加重"><a href="#2-2-1-预加重" class="headerlink" title="2.2.1 预加重"></a>2.2.1 预加重</h3><p>预加重其实就是将语音信号通过一个高通滤波器，来增强语音信号中的高频部分，并保持在低频到高频的整个频段中，能够使用同样的信噪比求频谱。在本实验中，选取的高通滤波器传递函数为：</p>
<p><img src="/images/speech-recognition/high_pass_filter.png"></p>
<p>式中a的值介于0.9-1.0之间，我们通常取0.97。同时，预加重也是为了消除发生过程中声带和嘴唇的效应，来补偿语音信号受到发音系统所抑制的高频部分，也为了突出高频的共振峰。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pre_emphasis</span>(<span class="params">signal, coefficient=<span class="number">0.97</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;对信号进行预加重&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> numpy.append(signal[<span class="number">0</span>], signal[<span class="number">1</span>:] - coefficient * signal[:-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-分帧"><a href="#2-2-2-分帧" class="headerlink" title="2.2.2 分帧"></a>2.2.2 分帧</h3><p>分帧是指在跟定的音频样本文件中，按照某一个固定的时间长度分割，分割后的每一片样本，称之为一帧，这里需要区分时域波形中的帧，分割后的一帧是分析提取MFCC的样本，而时域波形中的帧是时域尺度上对音频的采样而取到的样本。</p>
<p>分帧是先将N个采样点集合成一个观测单位，也就是分割后的帧。通常情况下N的取值为512或256，涵盖的时间约为20-30ms。也可以根据特定的需要进行N值和窗口间隔的调整。为了避免相邻两帧的变化过大，会让两相邻帧之间有一段重叠区域，此重叠区域包含了M个取样点，一般M的值约为N的1&#x2F;2或1&#x2F;3。</p>
<p>语音识别中所采用的信号采样频率一般为8kHz或16kHz。以8kHz来说，若帧长度为256个采样点，则对应的时间长度是256&#x2F;8000×1000&#x3D;32ms。本次实验中所使用的采样率(Frames Per Second)16kHz，窗长25ms（400个采样点），窗间隔为10ms（160个采样点）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">audio2frame</span>(<span class="params">signal, frame_length, frame_step, winfunc=<span class="keyword">lambda</span> x: numpy.ones(<span class="params">(<span class="params">x,</span>)</span>)</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;分帧&#x27;&#x27;&#x27;</span></span><br><span class="line">    signal_length = <span class="built_in">len</span>(signal)</span><br><span class="line">    frame_length = <span class="built_in">int</span>(<span class="built_in">round</span>(frame_length))</span><br><span class="line">    frame_step = <span class="built_in">int</span>(<span class="built_in">round</span>(frame_step))</span><br><span class="line">    <span class="keyword">if</span> signal_length &lt;= frame_length:</span><br><span class="line">        frames_num = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        frames_num = <span class="number">1</span> + <span class="built_in">int</span>(math.ceil((<span class="number">1.0</span> * signal_length - frame_length) / frame_step))</span><br><span class="line">    pad_length = <span class="built_in">int</span>((frames_num - <span class="number">1</span>) * frame_step + frame_length)</span><br><span class="line">    zeros = numpy.zeros((pad_length - signal_length,))</span><br><span class="line">    pad_signal = numpy.concatenate((signal, zeros))</span><br><span class="line">    indices = numpy.tile(numpy.arange(<span class="number">0</span>, frame_length), (frames_num, <span class="number">1</span>)) + numpy.tile(numpy.arange(<span class="number">0</span>, frames_num * frame_step, frame_step),(frame_length, <span class="number">1</span>)).T</span><br><span class="line">    indices = numpy.array(indices, dtype=numpy.int32)</span><br><span class="line">    frames = pad_signal[indices]</span><br><span class="line">    win = numpy.tile(winfunc(frame_length), (frames_num, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> frames * win</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-加窗"><a href="#2-2-3-加窗" class="headerlink" title="2.2.3 加窗"></a>2.2.3 加窗</h3><p>在对音频进行分帧之后，需要对每一帧进行加窗，以增加帧左端和右端的连续性，减少频谱泄漏。在提取MFCC的时候，比较常用的窗口函数为Hamming窗。</p>
<p>假设分帧后的信号为 <em>S(n),n&#x3D;0,1,2…,N-1</em>，其中N为帧的大小，那么进行加窗的处理则为：</p>
<p><img src="/images/speech-recognition/fps_hamming1.jpg"></p>
<p>W(n)的形式如下：</p>
<p><img src="/images/speech-recognition/fps_hamming2.jpg"></p>
<p>不同的a值会产生不同的汉明窗，一般情况下a取值0.46。进行值替换后，W(n)则为：</p>
<p><img src="/images/speech-recognition/fps_hamming3.png"></p>
<p>对应的汉明窗时域波形类似下图：</p>
<p><img src="/images/speech-recognition/fps_hamming4.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">deframesignal</span>(<span class="params">frames, signal_length, frame_length, frame_step, winfunc=<span class="keyword">lambda</span> x: numpy.ones(<span class="params">(<span class="params">x,</span>)</span>)</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;加窗&#x27;&#x27;&#x27;</span></span><br><span class="line">    signal_length = <span class="built_in">round</span>(signal_length)</span><br><span class="line">    frame_length = <span class="built_in">round</span>(frame_length)</span><br><span class="line">    frames_num = numpy.shape(frames)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> numpy.shape(frames)[<span class="number">1</span>] == frame_length, <span class="string">&#x27;&quot;frames&quot;矩阵大小不正确，它的列数应该等于一帧长度&#x27;</span></span><br><span class="line">    indices = numpy.tile(numpy.arange(<span class="number">0</span>, frame_length), (frames_num, <span class="number">1</span>)) + numpy.tile(numpy.arange(<span class="number">0</span>, frames_num * frame_step, frame_step),(frame_length, <span class="number">1</span>)).T</span><br><span class="line">    indices = numpy.array(indices, dtype=numpy.int32)</span><br><span class="line">    pad_length = (frames_num - <span class="number">1</span>) * frame_step + frame_length</span><br><span class="line">    <span class="keyword">if</span> signal_length &lt;= <span class="number">0</span>:</span><br><span class="line">        signal_length = pad_length</span><br><span class="line">    recalc_signal = numpy.zeros((pad_length,))</span><br><span class="line">    window_correction = numpy.zeros((pad_length, <span class="number">1</span>))</span><br><span class="line">    win = winfunc(frame_length)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, frames_num):</span><br><span class="line">        window_correction[indices[i, :]] = window_correction[indices[i, :]] + win + <span class="number">1e-15</span></span><br><span class="line">        recalc_signal[indices[i, :]] = recalc_signal[indices[i, :]] + frames[i, :]</span><br><span class="line">    recalc_signal = recalc_signal / window_correction</span><br><span class="line">    <span class="keyword">return</span> recalc_signal[<span class="number">0</span>:signal_length]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-2-4-对信号进行离散傅立叶变换-DFT"><a href="#2-2-4-对信号进行离散傅立叶变换-DFT" class="headerlink" title="2.2.4 对信号进行离散傅立叶变换 (DFT)"></a>2.2.4 对信号进行离散傅立叶变换 (DFT)</h3><p>由于信号在时域上的变换通常很难看出信号的特性，所有通常将它转换为频域上的能量分布来观察，不同的能量分布，代表不同语音的特性。所以在进行了加窗处理后，还需要再经过离散傅里叶变换以得到频谱上的能量分布。对分帧加窗后的各帧信号进行快速傅里叶变换得到各帧的频谱。并对语音信号的频谱取模平方得到语音信号的功率谱。设语音信号的DFT为：</p>
<p><img src="/images/speech-recognition/dft1.png"></p>
<p>能量的分布为：</p>
<p><img src="/images/speech-recognition/dft2.png"></p>
<p>在本次实验中，采用DFT长度 N&#x3D;512，结果值保留前257个系数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">spectrum_magnitude</span>(<span class="params">frames, NFFT = <span class="number">512</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算每一帧经过FFT变幻以后的频谱的幅度，若frames的大小为N*L,则返回矩阵的大小为N*NFFT&#x27;&#x27;&#x27;</span></span><br><span class="line">    complex_spectrum = numpy.fft.rfft(frames, NFFT)</span><br><span class="line">    <span class="keyword">return</span> numpy.absolute(complex_spectrum)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spectrum_power</span>(<span class="params">frames, NFFT</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算每一帧傅立叶变换以后的功率谱&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / NFFT * numpy.square(spectrum_magnitude(frames, NFFT))</span><br></pre></td></tr></table></figure>

<p>下图是有频谱到功率谱的转换结果示意图：</p>
<p><img src="/images/speech-recognition/dft3.png"></p>
<h3 id="2-2-5-应用梅尔滤波器-Mel-Filterbank"><a href="#2-2-5-应用梅尔滤波器-Mel-Filterbank" class="headerlink" title="2.2.5 应用梅尔滤波器 (Mel Filterbank)"></a>2.2.5 应用梅尔滤波器 (Mel Filterbank)</h3><p>MFCC考虑到了人类的听觉特征，先将线性频谱映射到基于听觉感知的Mel非线性频谱中，然后转换到倒谱上。 在Mel频域内，人对音调的感知度为线性关系。举例来说，如果两段语音的Mel频率相差两倍，则人耳听起来两者的音调也相差两倍。Mel滤波器的本质其实是一个尺度规则，通常是将能量通过一组Mel尺度的三角形滤波器组，如定义有M个滤波器的滤波器组，采用的滤波器为三角滤波器，中心频率为 <em>f(m),m&#x3D;1,2…M</em>，M通常取22-26。f(m)之间的间隔随着m值的减小而缩小，随着m值的增大而增宽，如图所示：</p>
<p><img src="/images/speech-recognition/mel1.jpg"></p>
<p>从频率到Mel频率的转换公式为： </p>
<p> <img src="/images/speech-recognition/mel_hz.jpg"></p>
<p> 其中 f 为语音信号的频率，单位赫兹（Hz）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hz2mel</span>(<span class="params">hz</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;把频率hz转化为梅尔频率&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2595</span> * numpy.log10(<span class="number">1</span> + hz / <span class="number">700.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mel2hz</span>(<span class="params">mel</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;把梅尔频率转化为hz&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">700</span> * (<span class="number">10</span> ** (mel / <span class="number">2595.0</span>) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>假如有10个Mel滤波器（在实际应用中通常一组Mel滤波器组有26个滤波器。），首先要选择一个最高频率和最低频率，通常最高频率为8000Hz，最低频率为300Hz。使用从频率转换为Mel频率的公式将300Hz转换为401.25Mels，8000Hz转换为2834.99Mels，由于有10个滤波器，每个滤波器针对两个频率的样点，样点之间会进行重叠处理，因此需要12个点，意味着需要在401.25和2834.99之间再线性间隔出10个附加点，如：</p>
<p><em>m(i) &#x3D; 401.25,622.50,843.75,1065.00,1286.25,1507.50, 1728.74,1949.99,2171.24,2392.49,2613.74,2834.99</em></p>
<p>现在使用从Mel频率转换为频率的公式将它们转换回赫兹：</p>
<p><em>h(i) &#x3D; 300,517.33,781.90,1103.97,1496.04,1973.32,2554.33, 3261.62,4122.63,5170.76,6446.70,8000</em></p>
<p>将频率映射到最接近的DFT频率：</p>
<p><img src="/images/speech-recognition/mel2.png"></p>
<p><em>f(i) &#x3D; 9,16,25,35,47,63,81,104,132,165,206,256</em></p>
<p>于是，我们得到了一个由10个Mel滤波器构成的Mel滤波器组。</p>
<p><img src="/images/speech-recognition/mel3.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_filter_banks</span>(<span class="params">filters_num=<span class="number">20</span>, NFFT=<span class="number">512</span>, samplerate=<span class="number">16000</span>, low_freq=<span class="number">0</span>, high_freq=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算梅尔三角间距滤波器，该滤波器在第一个频率和第三个频率处为0，在第二个频率处为1&#x27;&#x27;&#x27;</span></span><br><span class="line">    low_mel = hz2mel(low_freq)</span><br><span class="line">    high_mel = hz2mel(high_freq)</span><br><span class="line">    mel_points = numpy.linspace(low_mel, high_mel, filters_num + <span class="number">2</span>)</span><br><span class="line">    hz_points = mel2hz(mel_points)</span><br><span class="line">    <span class="built_in">bin</span> = numpy.floor((NFFT + <span class="number">1</span>) * hz_points / samplerate)</span><br><span class="line">    fbank = numpy.zeros([filters_num, NFFT / <span class="number">2</span> + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">0</span>, filters_num):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">int</span>(<span class="built_in">bin</span>[j]), <span class="built_in">int</span>(<span class="built_in">bin</span>[j + <span class="number">1</span>])):</span><br><span class="line">            fbank[j, i] = (i - <span class="built_in">bin</span>[j]) / (<span class="built_in">bin</span>[j + <span class="number">1</span>] - <span class="built_in">bin</span>[j])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">int</span>(<span class="built_in">bin</span>[j + <span class="number">1</span>]), <span class="built_in">int</span>(<span class="built_in">bin</span>[j + <span class="number">2</span>])):</span><br><span class="line">            fbank[j, i] = (<span class="built_in">bin</span>[j + <span class="number">2</span>] - i) / (<span class="built_in">bin</span>[j + <span class="number">2</span>] - <span class="built_in">bin</span>[j + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> fbank</span><br></pre></td></tr></table></figure>

<h3 id="2-2-6-对频谱进行离散余弦变换-DCT"><a href="#2-2-6-对频谱进行离散余弦变换-DCT" class="headerlink" title="2.2.6 对频谱进行离散余弦变换 (DCT)"></a>2.2.6 对频谱进行离散余弦变换 (DCT)</h3><p>在上一步的基础上使⽤离散余弦变换，即进⾏了⼀个傅⽴叶变换的逆变换，得到倒谱系数。</p>
<p><img src="/images/speech-recognition/dct.png"></p>
<p>由此可以得到26个倒谱系数。只取其[2:13]个系数，第1个用能量的对数替代，这13个值即为所需的13个MFCC倒谱系数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lifter</span>(<span class="params">cepstra, L=<span class="number">22</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;升倒谱函数&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> L &gt; <span class="number">0</span>:</span><br><span class="line">        nframes, ncoeff = numpy.shape(cepstra)</span><br><span class="line">        n = numpy.arange(ncoeff)</span><br><span class="line">        lift = <span class="number">1</span> + (L / <span class="number">2</span>) * numpy.sin(numpy.pi * n / L)</span><br><span class="line">        <span class="keyword">return</span> lift * cepstra</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> cepstra</span><br></pre></td></tr></table></figure>

<h3 id="2-2-7-动态差分参数的提取（包括一阶微分系数和加速系数）"><a href="#2-2-7-动态差分参数的提取（包括一阶微分系数和加速系数）" class="headerlink" title="2.2.7 动态差分参数的提取（包括一阶微分系数和加速系数）"></a>2.2.7 动态差分参数的提取（包括一阶微分系数和加速系数）</h3><p>标准的倒谱参数MFCC只反映了语音参数的静态特性，语音的动态特性可以用这些静态特征的差分谱来描述。通常会把动、静态特征结合起来以有效提高系统的识别性能。差分参数的计算可以采用下面的公式：</p>
<p><img src="/images/speech-recognition/dlog.png"></p>
<p>上式中，d(t)表示第t个一阶微分，c(t)表示第t个倒谱系数，Q表示倒谱系数的阶数，K表示一阶导数的时间差，可取1或2。将上式的结果再代入就可以得到加速系数。</p>
<p>⾄此，我们计算到了了⾳频⽂件每⼀帧的39个Mel频率倒谱系数（13个MFCC+13个一阶微分系数+13个加速系数），这些即为一个语音文件的特征数据，这些特征数据可以运用在之后的分类中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">derivate</span>(<span class="params">feat, big_theta=<span class="number">2</span>, cep_num=<span class="number">13</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算一阶系数或者加速系数的一般变换公式&#x27;&#x27;&#x27;</span></span><br><span class="line">    result = numpy.zeros(feat.shape)</span><br><span class="line">    denominator = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> theta <span class="keyword">in</span> numpy.linspace(<span class="number">1</span>, big_theta, big_theta):</span><br><span class="line">        denominator = denominator + theta ** <span class="number">2</span></span><br><span class="line">    denominator = denominator * <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> numpy.linspace(<span class="number">0</span>, feat.shape[<span class="number">0</span>] - <span class="number">1</span>, feat.shape[<span class="number">0</span>]):</span><br><span class="line">        tmp = numpy.zeros((cep_num,))</span><br><span class="line">        numerator = numpy.zeros((cep_num,))</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> numpy.linspace(<span class="number">1</span>, cep_num, cep_num):</span><br><span class="line">            a = <span class="number">0</span></span><br><span class="line">            b = <span class="number">0</span></span><br><span class="line">            s = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> theta <span class="keyword">in</span> numpy.linspace(<span class="number">1</span>, big_theta, big_theta):</span><br><span class="line">                <span class="keyword">if</span> (t + theta) &gt; cep_num:</span><br><span class="line">                    a = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    a = feat[row][t + theta - <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">if</span> (t - theta) &lt; <span class="number">1</span>:</span><br><span class="line">                    b = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    b = feat[row][t - theta - <span class="number">1</span>]</span><br><span class="line">                s += theta * (a - b)</span><br><span class="line">            numerator[t - <span class="number">1</span>] = s</span><br><span class="line">        tmp = numerator * <span class="number">1.0</span> / denominator</span><br><span class="line">        result[row] = tmp</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><p>本文针对语音数据的特征提取方法—MFCC进行了简单的概述和实践，MFCC是音频特征处理中比较常用而且很有效的方法。当特征数据提取出来之后，就可以进一步的进行数据的归一化、标准化，然后应用于机器学习、神经网络等等模型训练算法中，以得到能够识别语音类别的模型。在实际的应用中，可能还需要考虑很多的其他因素，例如源语音数据的采集方法、采集时长、模型的构建方式、模型的部署方式等等因素，因此需要根据业务的具体场景，来进行平衡取舍，以达到识别的时效性、准确性等。</p>
<p>目前关于语音识别相关的研究还在持续中，目标是能够最小化成本的在移动端部署语音识别相关的功能，提高SDK在人工智能方便的能力等。</p>
<h2 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4. 参考资料"></a>4. 参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">Mel-frequency cepstrum</a></li>
<li><a target="_blank" rel="noopener" href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">Mel Frequency Cepstral Coefficient (MFCC) tutorial
</a></li>
<li><a target="_blank" rel="noopener" href="https://musicinformationretrieval.com/">Notes on Music Information Retrieval</a></li>
<li><a target="_blank" rel="noopener" href="http://www.cnblogs.com/daniel-D/p/3244718.html">机器学习中距离和相似性度量方法</a></li>
</ul>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/04/30/2019-03-14-cart/"><img class="fill" src="/images/cart/cover.jpg" alt="什么是决策树"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:33:12.097Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T06:33:12.097Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">17 分钟读完 (大约2597个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2019-03-14-cart/">什么是决策树</a></h1><div class="content"><p>决策树(Decision Tree）是在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy &#x3D; 系统的凌乱程度，使用算法ID3, C4.5和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。<br>决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。<br>分类树（决策树）是一种十分常用的分类方法。他是一种监管学习，所谓监管学习就是给定一堆样本，每个样本都有一组属性和一个类别，这些类别是事先确定的，那么通过学习得到一个分类器，这个分类器能够对新出现的对象给出正确的分类。这样的机器学习就被称之为监督学习。</p>
<h2 id="什么是决策树？"><a href="#什么是决策树？" class="headerlink" title="什么是决策树？"></a>什么是决策树？</h2><p>有的人可能听过一个词：<strong>CART</strong>，这个代表的意思是<strong>Classification And Regression Tree</strong>。它是一个分类和回归的决策树。它被分为两类，一类是<strong>分类决策树</strong>(Classification Trees)，另一个类是<strong>回归决策树</strong>(Regression Trees)。也就是我们要用这个决策树解决两类问题，一个分类问题一个回归问题。</p>
<p><img src="/images/cart/cart.png"></p>
<p>对于分类决策树，一般来说用于一些分类离散的数据，比如说人的性别是男或者女，水果的种类有苹果梨子等等都是离散的。反之回归决策树，那么对应的场景就是连续的数据，比如人的年龄或者室外的温度。当我们进行分类问题时，分类的组之间是无序的。这里首先介绍下什么是有序，可以举个例子比如年龄，又年龄大或者年龄小。那么对于性别问题，男或女，它是没有顺序的。本文要讲的是分类问题在决策树上的应用。</p>
<p>来看个例子，在一个二维平面上有两个颜色分组的数据，我们要用决策树算法来构建分类器。这里的决策树算法要做的事情就是不断用水平和竖直的线不断对平面进行分隔，直到某一个区域类只有红类或者绿类。如图所示，我们画出几条线对平面进行分隔。</p>
<p><img src="/images/cart/cart-split.png"></p>
<p>这样图中的红组和蓝组的数据点就被这些数据分隔开来了，但这组数据是为了方便展示而特地画成这个样子的，实际情况并不一定会出现这种比较清晰的分割线。那我们先看看第一条分割线，将其分割成了上下两块区域，虽然两边都是既有红色又有蓝色，但我们可以说分类的结果还是比较纯的。用复杂点的数学语言来说就是，我们正在寻找一条分隔线，可以是水平的也可以是竖直的，我们想要做一个优化的问题，需要最小化分隔后的基尼不纯度。什么叫纯，指的是分隔后的一边如果只有红点或者绿点，那么可以说这个分隔的结果是非常纯的，那么如果两边既有红也有蓝，那么就是不纯的。我们希望当我们添加一条分割线后，想要将两边的纯度和最小化。那么每一条的分割线的寻找实际上就是在做一个优化的问题，那么优化的对象可以是基尼不纯度，也可以是信息学中的熵。这里不做过多解释，只是展示下决策树是如果运作的。</p>
<p>画出第一条分隔线后如图可以得到两组分类结果，一个是x2小于或者不小于60，再然后我们画出第二条分割线，看出x1&lt;50是绿组，否则就是红组，接着再画出第三条分割线，x1&lt;70都是红组，再对x1&gt;70分隔，得出红组和绿组数据。</p>
<p><img src="/images/cart/cart-tree.png"></p>
<p>如图其实就是上述所说的工作流程，我们得到的每一片叶子都是比较纯的结果，如果在实际实际生活中，数据可能非常复杂，那么我们的树可能就非常非常大，枝节非常非常多。那么有的时候，有的枝节不一定非要到最后知道yes or no，也许可能在前面某个枝节就停止了。比如对于x2&lt;20这里不再继续分割，假设有个新的数据点落在了这个区域，它落在绿色的区域的概率比落在红色的概率要大，那么我们就可以把这一部分都划分到绿色组中，也就是说可以剪掉多余的枝节，也许它对于训练集是有意义的，但对于更多其他的数据来说，它可能就是个噪音，我们不需要知道这么详细的信息。那最终就没有这两片叶子，到前面一步就结束了。</p>
<p>决策树算法是个很经典的机器学习算法，很多年以前是比较流行的。但到了20世纪初已经逐渐被其他算法所取代。直到最近又发现这个算法中一些新的精妙的东西，比如说随机森林，就是以决策树为根本来展开的。还有提升梯度(Gradient Boosting)等等都是在决策树算法之上我们加上了一些新的元素。</p>
<p>代码实现<br>由于这次决策树算法，我们没有使用欧式距离，也就是说可以不用进行特征缩放。但最终画图像时之前模版中定义的步距可能就过大或者过小，所以这里就妥协一下保留特征缩放的代码。分类器改成决策树算法的DecisionTreeClassifier。这个方法的参数criterion指的就是标准，默认gini，即基尼指数或者说基尼不纯度。它和熵都是表示分类时划分质量的好坏。这里我们使用熵。其他的参数暂时用不到,random_state依然只是用来大家如果想得到相同的结果时就设置为相同的值即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">classifier = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>,random_state=)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>

<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>在开始讲随机森林之前我们先讲一个更为广义的概念: Ensemble Learning，集成学习。它的意思是我们使用多个分类器对我们的结果进行预测，最后再对分类结果进行一个组合，以达到最终的结果。这个组合的方式有很多种，比如平均，加权平均或者投票等等。这个集成学习的作用就是，我们觉得任何一个单独的分类器去分类结果回感觉有误差，这时可以用成百上千个分类器都进行预测，然后再对结果进行一个组合，可以减少预测结果的浮动率。下面来看看随机森林算法的步骤。</p>
<p>首先，随机采用训练集合中的数据，相当于装袋的过程，构建自己新的训练集；然后用这些数据训练决策树分类器；再然后实际上就是重复第一第二步，但每一次得到的结果是不同的，因为在第一步中我们取得的数据都是随机的。对于一个新的数据点，我们用已经训练好的多个训练器分别对这个新数据的分类进行预测，最后进行一个投票，拥有最大投票数量的分类结果胜出就使用这个分类结果。</p>
<p><img src="/images/cart/random-forest.png"></p>
<p>前文讲述了如何构建一棵决策树，现在拥有成百上千棵决策树来帮助我们解决分类问题。这个分类算法还有不少数学上的一些细节问题，比如Boosting(提升)，还有当我们有高维度的情况时，我们每次选取数据时可能只选取部分维度，这样可以避免个别维度比其他维度大的多情况。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>这里依然开始先套用分类的模版，然后换成随机森林分类器，这里的参数n_estimators指的是决策树的数量,这里暂时设置成10 criterion依然设置为entropy。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">classifier = RandomForestClassifier(n_estimators=<span class="number">10</span>, criterion=<span class="string">&#x27;entropy&#x27;</span>, random_state=<span class="number">0</span>)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>

<p>通过结果观察，这里使用随机森林分类器是会出现过拟合的情况。对比这几篇文章中的分类器，实际上最适合的是核svm和朴素贝叶斯，线性分类器准确度不够，随机森林分类器会出现过拟合，而这两者它们保证了拟合的准确率，并且也不会出现过拟合的问题。</p>
</div></article></div><div class="card"><div class="card-image"><a class="image is-7by3" href="/2022/04/30/2018-09-18-ML_in_finance/"><img class="fill" src="/images/ML_in_finance/ML_in_finance-infographic-011.jpg" alt="金融领域的机器学习：为什么、是什么、怎么做"></a></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-04-30T06:33:12.084Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>发表</span><span class="level-item"><time dateTime="2022-04-30T06:33:12.084Z" title="4/30/2022, 2:33:12 PM">2022-04-30</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">33 分钟读完 (大约4933个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/30/2018-09-18-ML_in_finance/">金融领域的机器学习：为什么、是什么、怎么做</a></h1><div class="content"><p>现如今，机器学习的发展可谓如火如荼，尤其是在金融领域，机器学习似乎具有了某种魔法，应用可谓非常广泛。尽管如此，机器学习项目的成功更多地取决于构建高效的基础架构，收集合适的数据以及应用正确的算法几个方面。</p>
<p>可以看到的是，机器学习正在金融服务行业取得重大的进展。那么为什么金融类企业应该关心机器学习乃至深度学习，以及可以通过AI和机器学习实现哪些细分领域的解决方案和如何应用这项技术。</p>
<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>我们可以将<strong>机器学习定义为数据科学的一个子集</strong>，它使用统计模型来绘制具有一定洞察力的模式并进行预测推理。下图解释了人工智能、数据科学和机器学习之间的相互关系。为了简单起见，这篇文章中仅关注机器学习部分。</p>
<p>机器学习解决方案的奇妙之处在于，它们可以从经验中学习而无明确的编码指向，简而言之，你只需要选择合适的模型并将数据提供给它们，然后，模型会自动调整其参数以改善模型结果。</p>
<p>数据科学家使用现有的数据集训练机器学习模型，然后将训练有素的模型应用于现实应用中。模型会在后台进程运行，并根据其训练的方式自动提供结果。数据科学家可以根据需要重新训练模型，以保证模型的最新和有效。例如<a target="_blank" rel="noopener" href="https://mercanto.app/">Mercanto</a>会每天重新训练机器学习模型。</p>
<p>通常情况下，你提供的<strong>数据越多</strong>，机器学习模型的<strong>结果就越准确</strong>。巧合的是，庞大的数据集在金融服务行业非常普遍，例如交易数据、客户数据、账单数据、资金流水数据等有数PB的数据量，而这恰恰非常适合机器学习。</p>
<p>伴随着技术的发展和一些优质算法的开源，很难想象没有机器学习的金融服务的未来会是怎样的。</p>
<p>也就是说，<strong>大多数的金融服务企业</strong>仍然没有准备好从这项技术中提取真正的价值，可能的原因如下：</p>
<ol>
<li>企业往往对机器学习及其组织的价值抱有完全不切实际的期望。</li>
<li>人工智能和机器学习研究和开发成本很高。</li>
<li>数据科学家&#x2F;机器学习工程师的短缺是另一个主要问题。下图显示了人工智能和机器学习技能需求的爆炸性增长：</li>
<li>在更新数据基础架构方面，金融老牌企业不够灵活和积极。</li>
</ol>
<p><img src="/images/ML_in_finance/ML_in_finance-infographic-05.jpg"></p>
<p>我们将在本文稍后讨论如何克服这些问题。首先，让我们看看为什么金融服务公司不能忽视机器学习。</p>
<h1 id="金融领域，为什么要考虑机器学习？"><a href="#金融领域，为什么要考虑机器学习？" class="headerlink" title="金融领域，为什么要考虑机器学习？"></a>金融领域，为什么要考虑机器学习？</h1><p>尽管面临各种挑战，但许多金融公司已经利用了这项技术。下图显示金融服务的高管非常重视机器学习，并且出于以下原因：</p>
<p><img src="/images/ML_in_finance/ML_in_finance-infographic-02.jpg"></p>
<ol>
<li>由于过程自动化，降低了运营成本。</li>
<li>通过提高生产力和增强用户体验，增加收入。</li>
<li>更好地遵守和加强安全性。</li>
</ol>
<p>有各种各样的开源机器学习算法和工具，可以很好地适应财务数据。此外，成熟的金融服务公司拥有大量资金，他们可以负担得起在最先进的计算硬件上的花费。</p>
<h1 id="金融领域的机器学习用例是什么？"><a href="#金融领域的机器学习用例是什么？" class="headerlink" title="金融领域的机器学习用例是什么？"></a>金融领域的机器学习用例是什么？</h1><p>让我们来看看金融领域一些有前景的机器学习应用程序。</p>
<p><img src="/images/ML_in_finance/ML_in_finance-infographic-071-1.jpg"></p>
<h2 id="过程自动化"><a href="#过程自动化" class="headerlink" title="过程自动化"></a>过程自动化</h2><p>过程自动化是机器学习在金融领域最常见的应用之一。该技术可以替代手动工作，自动执行重复性任务并提高生产率。</p>
<p>因此，机器学习使公司能够优化成本，改善客户体验并扩展服务。以下是金融机器学习的自动化用例：</p>
<ul>
<li>会话机器人</li>
<li>呼叫中心自动化</li>
<li>文书工作自动化</li>
<li>员工培训的游戏化等等。</li>
</ul>
<p>以下是银行业务流程自动化的一些示例：</p>
<p><strong>JPMorgan Chase</strong>推出了一个合约智能（COiN）平台，该平台利用自然语言处理技术，这是一种机器学习技术。该解决方案处理法律文件并从中提取重要数据。对12,000份年度商业信贷协议进行人工审查通常需要约360,000个工时。然而，机器学习允许在短短几个小时内审查相同数量的合同。</p>
<p><strong>BNY Mello</strong> 将流程自动化集成到他们的银行生态系统中。这项创新每年可节省30万美元，并带来了广泛的运营改进。</p>
<p><strong>Wells Fargo</strong> 通过Facebook Messenger平台使用AI驱动的聊天机器人与用户进行通信，并提供密码和帐户的帮助。</p>
<p><strong>Privatbank</strong> 是一家乌克兰银行，通过其移动和网络平台实施聊天机器人助理。 Chatbots加快了一般客户查询的解决速度，并允许减少人工助理的数量。</p>
<h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>随着交易，用户和第三方集成的数量不断增加，财务中的安全威胁也在不断增加。机器学习算法非常适合<strong>检测欺诈行为</strong>。</p>
<p>例如，银行可以使用该技术实时监控每个账户的数千个交易参数。该算法检查持卡人采取的每个动作，并评估尝试的活动是否是该特定用户的特征。这种模型具有高精度的欺诈行为。</p>
<p>如果系统识别可疑帐户行为，则可以请求用户提供额外的标识以验证交易。如果至少有95％的可能性是欺诈行为，甚至可以完全阻止交易。机器学习算法只需几秒钟来评估交易。速度有助于实时防止欺诈，而不仅仅是在犯罪发生后发现它们。</p>
<p><strong>财务监控</strong> 是金融机器学习的另一个安全用例。数据科学家可以训练系统检测大量小额支付，并将这种洗钱技术标记为smurfing。</p>
<p>机器学习算法也可以显著增强网络安全性。数据科学家训练系统发现和隔离网络威胁，因为机器学习在分析数千个参数和实时时是首屈一指的。这项技术有可能在最近的将来为最先进的网络安全网络提供支持。</p>
<p>Adyen，Payoneer，Paypal，Stripe和Skrill是一些值得注意的金融科技公司，他们在安全机器学习方面投入巨资。</p>
<p><img src="/images/ML_in_finance/ML_in_finance-infographic-03.jpg"></p>
<h2 id="承保和信用评分"><a href="#承保和信用评分" class="headerlink" title="承保和信用评分"></a>承保和信用评分</h2><p>机器学习算法完全适合金融和保险中常见的承保任务。 </p>
<p>数据科学家在数千个客户档案中训练模型，为每个客户提供数百个数据条目。然后，训练有素的系统可以在现实环境中执行相同的承保和信用评分任务。这种评分引擎可以帮助人员更快，更准确地工作。</p>
<p>银行和保险公司拥有大量历史消费者数据，因此他们可以使用这些条目来培训机器学习模型。或者，他们可以利用大型电信或公用事业公司生成的数据集。 </p>
<p>例如，BBVA Bancomer正与另一个信用评分平台Destacame合作。该银行旨在为拉丁美洲信用记录薄的客户增加信贷准入。 Destacame通过开放API访问公用事业公司的账单支付信息。使用账单支付行为，Destacame为客户生成信用评分并将结果发送给银行。</p>
<h2 id="算法交易"><a href="#算法交易" class="headerlink" title="算法交易"></a>算法交易</h2><p>在算法交易中，机器学习有助于做出更好的交易决策。数学模型实时监控新闻和交易结果，并检测可能迫使股价上涨或下跌的模式。然后，它可以根据其预测主动出售，持有或购买股票。 </p>
<p>机器学习算法可以同时分析数千个数据源，这是人类交易者无法实现的。 </p>
<p>机器学习算法可以帮助人类交易者在市场平均水平上占据一席之地。而且，鉴于大量的交易操作，这种小优势通常会转化为巨额利润。</p>
<h2 id="机器人顾问"><a href="#机器人顾问" class="headerlink" title="机器人顾问"></a>机器人顾问</h2><p>机器人顾问现在在金融领域司空见惯。目前，在咨询领域中有两种主要的机器学习应用：</p>
<p><strong>投资组合管理</strong> 是一种在线财富管理服务，它使用算法和统计数据来分配，管理和优化客户的资产。用户输入他们目前的金融资产和目标，例如，在50岁时节省一百万美元。机器人顾问然后根据风险偏好和期望目标在投资机会中分配当前资产。 </p>
<p><strong>金融产品推荐</strong> 许多在线保险服务使用机器人顾问向特定用户推荐个性化保险计划。由于费用较低，客户选择机器人顾问而不是个人理财顾问，以及个性化和校准的推荐。</p>
<p><img src="/images/ML_in_finance/ML_banner-1024x375.jpg"></p>
<h1 id="金融领域如何使用机器学习？"><a href="#金融领域如何使用机器学习？" class="headerlink" title="金融领域如何使用机器学习？"></a>金融领域如何使用机器学习？</h1><p>尽管人工智能和机器学习具有所有优势，但即使是拥有雄厚财力的公司也很难从这项技术中获取真正的价值。金融服务公司希望利用机器学习的独特机会，但实际上，他们对数据科学如何运作以及如何使用它有一个模糊的概念。 他们一次又遇到类似的挑战，例如缺乏业务KPI。反过来，这会导致不切实际的估计并导致预算耗尽。拥有合适的软件基础设施是不够的（尽管这将是一个良好的开端）。它需要一个清晰的愿景，扎实的技术人才，以及提供有价值的机器学习开发项目的决心。 </p>
<p>一旦您充分了解此技术将如何帮助实现业务目标，请继续进行构思验证。这是数据科学家的任务。他们调查这个想法，帮助您制定可行的KPI并做出切合实际的估算。 请注意，此时您需要收集所有数据。否则，您需要数据工程师来收集和清理这些数据。 根据具体的使用案例和业务条件，金融公司可以采用不同的途径来采用机器学习。我们来看看吧。</p>
<h2 id="放弃机器学习，转而专注于大数据工程"><a href="#放弃机器学习，转而专注于大数据工程" class="headerlink" title="放弃机器学习，转而专注于大数据工程"></a>放弃机器学习，转而专注于大数据工程</h2><p>通常，金融公司开始他们的机器学习项目只是为了意识到他们只需要适当的数据工程。 N-iX的高级数据科学家Max Nechepurenko评论道：</p>
<blockquote>
<p>在开发[数据科学]解决方案时，我建议使用Occam的剃刀原理，这意味着不会过度复杂。大多数以机器学习为目标的公司实际上需要关注可靠的数据工程，将统计数据应用于聚合数据以及对数据进行可视化。</p>
</blockquote>
<p>仅仅将统计模型应用于处理过的和结构良好的数据就足以让银行隔离其运营中的各种瓶颈和低效率。</p>
<p>这种瓶颈有哪些例子？这可能是特定分支的队列，可以消除的重复性任务，低效的人力资源活动，移动银行应用程序的缺陷等等。 </p>
<p>更重要的是，任何数据科学项目中最重要的部分都归结为构建一个协调的平台生态系统，从数百个来源（如CRM，报告软件，电子表格等）收集孤立的数据。 </p>
<p>在应用任何算法之前，您需要对数据进行适当的结构化和清理。只有这样，您才能进一步将这些数据转化为洞察力。事实上，ETL（提取，转换和加载）和进一步清理数据占机器学习项目时间的80％左右。</p>
<p><img src="/images/ML_in_finance/ML_in_finance-infographic-04.jpg"></p>
<h2 id="使用第三方机器学习解决方案"><a href="#使用第三方机器学习解决方案" class="headerlink" title="使用第三方机器学习解决方案"></a>使用第三方机器学习解决方案</h2><p>即使您的公司决定在即将开展的项目中使用机器学习，您也不一定需要开发新的算法和模型。 </p>
<p>大多数机器学习项目都处理已经解决的问题。谷歌，微软，亚马逊和IBM等科技巨头将机器学习软件作为一种服务出售。 </p>
<p>这些开箱即用的解决方案已经过培训，可以解决各种业务任务。如果您的项目涉及相同的用例，您是否认为您的团队可以通过庞大的研发中心超越这些技术巨头的算法？ 一个很好的例子是Google的多种即插即用推荐解决方案。该软件适用于各种域，检查它们是否适合您的业务案例是合乎逻辑的。 </p>
<p>机器学习工程师可以实施专注于您的特定数据和业务领域的系统。专家需要从不同来源提取数据，将其转换为适合此特定系统，接收结果并可视化结果。 </p>
<p>权衡取舍是缺乏对第三方系统的控制和有限的解决方案灵活性。此外，机器学习算法并不适合每个用例。 N-iX高级数据科学家Ihar Rubanau评论道：</p>
<blockquote>
<p>尚不存在通用机器学习算法。数据科学家需要在将算法应用于不同领域的不同业务案例之前对其进行调整和微调。</p>
</blockquote>
<p>因此，如果Google的现有解决方案解决了您特定域中的特定任务，您应该使用它。如果没有，请致力于定制开发和集成。</p>
<h2 id="创新与整合"><a href="#创新与整合" class="headerlink" title="创新与整合"></a>创新与整合</h2><p>从头开始开发机器学习解决方案是风险最大，成本最高且耗时的选择之一。尽管如此，这可能是将ML技术应用于某些商业案例的唯一方法。 </p>
<p>机器学习研究和开发针对特定利基市场的独特需求，并要求进行深入调查。如果没有为解决这些特定问题而开发的现成解决方案，则第三方机器学习软件可能会产生不准确的结果。</p>
<p><img src="/images/ML_in_finance/ML_in_finance-infographic-06.jpg"></p>
<p>不过，您可能需要严重依赖Google等开源机器学习库。当前的机器学习项目主要是将现有的最先进的库应用于特定的域和用例。</p>
<p>在N-iX，我们确定了机器学习中成功的企业研发项目的七个共同特征。他们是：</p>
<ol>
<li><strong>一个明确的目标</strong>。在收集数据之前，您至少需要对通过AI和机器学习实现的结果有一些大致的了解。在项目的早期阶段，数据科学家将帮助您将这一想法转化为实际的KPI。 </li>
<li><strong>机器学习解决方案的强大架构设计</strong>。您需要经验丰富的软件架构师来执行此任务。 </li>
<li><strong>适当的大数据工程生态系统是必不可少的</strong>（基于Apache Hadoop或Spark）。它允许从金融服务公司的众多孤立数据源中收集，集成，存储和处理大量数据。大数据架构师和大数据工程师负责构建生态系统。 </li>
<li><strong>在新创建的生态系统上运行ETL过程</strong>（提取，转换和加载）。大数据架构师或机器学习工程师执行此任务。 </li>
<li><strong>最后的数据准备</strong>。除数据转换和技术清理外，数据科学家可能还需要进一步优化数据，使其适用于特定的业务案例。 </li>
<li><strong>应用适当的算法</strong>，基于这些算法创建模型，微调模型以及使用新数据重新训练模型。数据科学家和机器学习工程师执行这些任务。 </li>
<li><strong>清晰可见的洞察力</strong>。商业智能专家对此负责。此外，您可能需要前端开发人员创建具有易于使用的UI的仪表板。</li>
</ol>
<p>小型项目可能需要更少的工作量和更小的团队。例如，一些研发项目涉及小型数据集，因此他们可能不需要复杂的大数据工程。在其他情况下，根本不需要复杂的仪表板或任何数据可视化。</p>
<h1 id="关键要点"><a href="#关键要点" class="headerlink" title="关键要点"></a>关键要点</h1><ul>
<li>金融老牌企业最常使用机器学习来实现流程自动化和安全性。 </li>
<li>在收集数据之前，您需要清楚地了解数据科学所期望的结果。</li>
<li>在项目开始之前，需要设置可行的KPI并做出切合实际的估算。 </li>
<li>许多金融服务公司需要数据工程，统计和数据可视化，而不是数据科学和机器学习。 </li>
<li>训练数据集越大越清洁，机器学习解决方案产生的结果就越准确。 您可以根据需要随时重新训练模型，而无需停止机器学习算法。 </li>
<li>没有通用的机器学习解决方案适用于不同的业务案例。 </li>
<li>具有机器学习功能的财务软件的开发成本很高。 </li>
<li>像谷歌这样的科技巨头创造了机器学习解决方案。如果您的项目涉及此类用例，那么您不能指望其优于Google，Amazon或IBM的算法。</li>
</ul>
<blockquote>
<p>原文地址：<a target="_blank" rel="noopener" href="https://www.n-ix.com/machine-learning-in-finance-why-what-how/">https://www.n-ix.com/machine-learning-in-finance-why-what-how/</a></p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-02-19T07:01:13.565Z" title="2/19/2021, 3:01:13 PM">2021-02-19</time>发表</span><span class="level-item"><time dateTime="2021-02-19T07:01:13.565Z" title="2/19/2021, 3:01:13 PM">2021-02-19</time>更新</span><span class="level-item"> Robin </span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">7 分钟读完 (大约1093个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/19/2019-01-22-data_cleaning/">8大场景数据清洗Python代码</a></h1><div class="content"><p><strong>数据清洗</strong>是进行数据分析和使用数据训练模型的必经之路，也是最为耗费数据科学家、程序员的地方。</p>
<p>在数据清洗的过程中，绝大多数的场景下，所进行的清洗工作都是相似甚至是重复的，因此有必要将数据清洗工作的场景进行总结并给出对应的清洗代码，以便形成可适用于多数工程项目的工具箱。</p>
<hr>
<h1 id="涵盖8大场景的数据清洗代码"><a href="#涵盖8大场景的数据清洗代码" class="headerlink" title="涵盖8大场景的数据清洗代码"></a>涵盖8大场景的数据清洗代码</h1><p>以下数据清洗代码，涵盖了8个数据清洗工作中常见的场景，分别是：</p>
<ol>
<li>删除多列</li>
<li>转换数据类型</li>
<li>将分类变量转换为数字变量</li>
<li>检查缺失数据</li>
<li>删除列中的字符串</li>
<li>删除列中的空格</li>
<li>用字符串连接两列（带条件）</li>
<li>转换时间戳（从字符串到日期时间格式）</li>
</ol>
<h2 id="1-删除多列"><a href="#1-删除多列" class="headerlink" title="1. 删除多列"></a>1. 删除多列</h2><p>在进行数据分析时，可能并非所有的列都有用，此时可以使用<code>df.drop</code>方便地删除指定的列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drop_multiple_col</span>(<span class="params">col_name_list, df</span>):</span><br><span class="line">	df.drop(col_name_list, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">	<span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>

<h2 id="2-转换数据类型"><a href="#2-转换数据类型" class="headerlink" title="2. 转换数据类型"></a>2. 转换数据类型</h2><p>当数据集变大时，可能需要转换数据类型来节省内存空间：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">change_dtypes</span>(<span class="params">col_int, col_float, df</span>):</span><br><span class="line">	df[col_int] = df[col_int].astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">	df[col_float] = df[col_float].astype(<span class="string">&#x27;float32&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-将分类变量转换为数字变量"><a href="#3-将分类变量转换为数字变量" class="headerlink" title="3. 将分类变量转换为数字变量"></a>3. 将分类变量转换为数字变量</h2><p>在一些机器学习模型中，会要求变量采用数值格式。此时便需要将分类变量转换为数字变量，同时，也可以保留分类变量，以便进行数据可视化等：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convert_cat_2num</span>(<span class="params">df</span>):</span><br><span class="line">	num_encode = &#123;<span class="string">&#x27;col_1&#x27;</span> : &#123;<span class="string">&#x27;YES&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;NO&#x27;</span>:<span class="number">0</span>&#125;,</span><br><span class="line">				  <span class="string">&#x27;col_2&#x27;</span> : &#123;<span class="string">&#x27;WON&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;LOSE&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;DRAW&#x27;</span>:<span class="number">0</span>&#125;&#125;</span><br><span class="line">	df.replace(num_encode, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-检查缺失数据"><a href="#4-检查缺失数据" class="headerlink" title="4. 检查缺失数据"></a>4. 检查缺失数据</h2><p>如果要检查每列缺失数据的数量，可使用下面的代码，目前来看应该是最快的方法。可以更好地了解哪些列缺失的数据更多，从而确定怎么进行下一步的数据清洗和分析操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">check_missing_data</span>(<span class="params">df</span>):</span><br><span class="line">	<span class="keyword">return</span> df.isnull().<span class="built_in">sum</span>().sort_values(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h2 id="5-删除列中的字符串"><a href="#5-删除列中的字符串" class="headerlink" title="5. 删除列中的字符串"></a>5. 删除列中的字符串</h2><p>有时，会有新的字符或者其他不需要的符号出现在字符串中，此时可以使用<code>df[&#39;col_1&#39;].replace</code>将它们处理掉：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">remove_col_str</span>(<span class="params">df</span>):</span><br><span class="line">	df[<span class="string">&#x27;col_1&#x27;</span>].replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>, regex=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">	df[<span class="string">&#x27;col_1&#x27;</span>].replace(<span class="string">&#x27; &amp;#.*&#x27;</span>, <span class="string">&#x27;&#x27;</span>, regex=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="6-删除列中的空格"><a href="#6-删除列中的空格" class="headerlink" title="6. 删除列中的空格"></a>6. 删除列中的空格</h2><p>当数据混乱的时候，什么情况都有可能发生。字符串开头有时会有一些空格，在删除列中字符串开头的空格时，可使用下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">remove_col_white_space</span>(<span class="params">col, df</span>):</span><br><span class="line">	df[col] = df[col].<span class="built_in">str</span>.lstrip()</span><br></pre></td></tr></table></figure>

<h2 id="7-用字符串连接两列（带条件）"><a href="#7-用字符串连接两列（带条件）" class="headerlink" title="7. 用字符串连接两列（带条件）"></a>7. 用字符串连接两列（带条件）</h2><p>当你想要有条件地用字符串将两列连接在一起时，这段代码很有帮助。比如，你可以在第一列结尾处设定某些字母，然后用它们与第二列连接在一起。</p>
<p>根据需要，结尾处的字母也可以在连接完成后删除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">concat_col_str_condition</span>(<span class="params">df</span>):</span><br><span class="line">    mask = df[<span class="string">&#x27;col_1&#x27;</span>].<span class="built_in">str</span>.endswith(<span class="string">&#x27;pil&#x27;</span>, na=<span class="literal">False</span>)</span><br><span class="line">    col_new = df[mask][<span class="string">&#x27;col_1&#x27;</span>] + df[mask][<span class="string">&#x27;col_2&#x27;</span>]</span><br><span class="line">    col_new.replace(<span class="string">&#x27;pil&#x27;</span>, <span class="string">&#x27; &#x27;</span>, regex=<span class="literal">True</span>, inplace=<span class="literal">True</span>)  <span class="comment"># replace the &#x27;pil&#x27; with emtpy space</span></span><br></pre></td></tr></table></figure>

<h2 id="8-转换时间戳（从字符串到日期时间格式）"><a href="#8-转换时间戳（从字符串到日期时间格式）" class="headerlink" title="8. 转换时间戳（从字符串到日期时间格式）"></a>8. 转换时间戳（从字符串到日期时间格式）</h2><p>在处理时间序列数据时，我们很可能会遇到字符串格式的时间戳列。</p>
<p>这意味着要将字符串格式转换为日期时间格式(或者其他根据我们的需求指定的格式) ，以便对数据进行有意义的分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">convert_str_datetime</span>(<span class="params">df</span>): </span><br><span class="line">    df.insert(loc=<span class="number">2</span>, column=<span class="string">&#x27;timestamp&#x27;</span>, value=pd.to_datetime(df.transdate, <span class="built_in">format</span>=<span class="string">&#x27;%Y-%m-%d %H:%M:%S.%f&#x27;</span>)) </span><br></pre></td></tr></table></figure>

<p>以上便是针对8个常见场景的数据清洗代码，在部分场景下，你可能需要简单修改代码才可使用。在面对各种不同且复杂的数据时，可能需要先了解你的数据，然后再决定使用那个或者那些方法进行数据的清洗工作，使得数据能够更好的进入下一步的分析建模过程等。</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Robin&#039;s Wo"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Robin&#039;s Wo</p><p class="is-size-6 is-block">Robin</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国·西安</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">60</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/zycslog" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zycslog"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/zh_robin"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Data-Structures-Algorithms-in-Swift/"><span class="level-start"><span class="level-item">Data Structures &amp; Algorithms in Swift</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/categories/Logs/"><span class="level-start"><span class="level-item">Logs</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86/"><span class="level-start"><span class="level-item">开发知识</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%94%9F/"><span class="level-start"><span class="level-item">技术人生</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"><span class="level-start"><span class="level-item">数据科学</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AB%AF%E6%B5%8B%E8%AE%A1%E7%AE%97/"><span class="level-start"><span class="level-item">端测计算</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AF%BB%E4%B9%A6%E5%B0%8F%E8%AE%B0/"><span class="level-start"><span class="level-item">读书小记</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">七月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">49</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">二月 2021</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.williamlong.info/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">月光博客</span></span><span class="level-right"><span class="level-item tag">www.williamlong.info</span></span></a></li><li><a class="level is-mobile" href="https://zhangferry.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">zhangferry</span></span><span class="level-right"><span class="level-item tag">zhangferry.com</span></span></a></li><li><a class="level is-mobile" href="https://xcanoe.top/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">轻舟</span></span><span class="level-right"><span class="level-item tag">xcanoe.top</span></span></a></li><li><a class="level is-mobile" href="https://iosdevweekly.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">iOS Dev Weekly</span></span><span class="level-right"><span class="level-item tag">iosdevweekly.com</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/avatar.jpg" alt="Robin&#039;s Wo" height="28"></a><p class="is-size-7"><span>&copy; 2022 Robin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/zycslog"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>